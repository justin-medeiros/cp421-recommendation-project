{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "va5H-Oe6OPF7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff4UOlhiOPF-",
        "outputId": "a6aa3809-8ed6-496b-fae6-e84b43a9ea40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/tz/f5wwvbqj0sjgxsr35rx5h1k00000gs/T/ipykernel_5896/348323183.py:10: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  books_df = pd.read_csv(books_file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Data after preprocessing:\n",
            "Unique values in 'Year-Of-Publication': [2002. 2001. 1991. 1999. 2000. 1993. 1996. 1988. 2004. 1998. 1994. 2003.\n",
            " 1997. 1983. 1979. 1995. 1982. 1985. 1992. 1986. 1978. 1980. 1952. 1987.\n",
            " 1990. 1981. 1989. 1984.    0. 1968. 1961. 1958. 1974. 1976. 1971. 1977.\n",
            " 1975. 1965. 1941. 1970. 1962. 1973. 1972. 1960. 1966. 1920. 1956. 1959.\n",
            " 1953. 1951. 1942. 1963. 1964. 1969. 1954. 1950. 1967. 2005. 1957. 1940.\n",
            " 1937. 1955. 1946. 1936. 1930. 2011. 1925. 1948. 1943. 1947. 1945. 1923.\n",
            " 2020. 1939. 1926. 1938. 2030. 1911. 1904. 1949. 1932. 1928. 1929. 1927.\n",
            " 1931. 1914. 2050. 1934. 1910. 1933. 1902. 1924. 1921. 1900. 2038. 2026.\n",
            " 1944. 1917. 1901. 2010. 1908. 1906. 1935. 1806. 2021. 2012. 2006. 1909.\n",
            " 2008. 1378. 1919. 1922. 1897. 2024. 1376. 2037.]\n",
            "\n",
            "Missing values after preprocessing:\n",
            "Users: User-ID     0\n",
            "Location    0\n",
            "Age         0\n",
            "dtype: int64\n",
            "Books: ISBN                   0\n",
            "Book-Title             0\n",
            "Book-Author            0\n",
            "Year-Of-Publication    0\n",
            "Publisher              0\n",
            "dtype: int64\n",
            "Ratings: User-ID        0\n",
            "ISBN           0\n",
            "Book-Rating    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#DATA PRECPROCESSING-----------------------------------------------------------------------------------------------\n",
        "\n",
        "# File paths\n",
        "users_file = 'Users.csv'\n",
        "books_file = 'Books.csv'\n",
        "ratings_file = 'Ratings.csv'\n",
        "\n",
        "# Load the datasets\n",
        "users_df = pd.read_csv(users_file)\n",
        "books_df = pd.read_csv(books_file)\n",
        "ratings_df = pd.read_csv(ratings_file)\n",
        "\n",
        "# Users Data Preprocessing\n",
        "# Handle missing values in 'Age' and 'Location'\n",
        "users_df['Age'].fillna(users_df['Age'].median(), inplace=True)\n",
        "users_df['Location'].fillna('Unknown', inplace=True)\n",
        "\n",
        "\n",
        "# Books Data Preprocessing\n",
        "# Convert 'Year-Of-Publication' to numeric and handle non-numeric values\n",
        "books_df['Year-Of-Publication'] = pd.to_numeric(books_df['Year-Of-Publication'], errors='coerce')\n",
        "books_df['Year-Of-Publication'].fillna(books_df['Year-Of-Publication'].median(), inplace=True)\n",
        "# Handle missing values in 'Book-Author' and 'Publisher'\n",
        "books_df['Book-Author'].fillna('Unknown', inplace=True)\n",
        "books_df['Publisher'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Drop the url columns as we will not be using them\n",
        "books_df.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis=1, inplace=True)\n",
        "\n",
        "# Ratings Data Preprocessing\n",
        "# Merge 'Ratings' with 'Books' to filter out books not in the 'Books' dataset\n",
        "ratings_df = ratings_df[ratings_df['ISBN'].isin(books_df['ISBN'])]\n",
        "\n",
        "# Merge books_df, users_df, and ratings_df\n",
        "merged_df = pd.merge(ratings_df, books_df, on='ISBN', how='inner')\n",
        "merged_df = pd.merge(merged_df, users_df, on='User-ID', how='inner')\n",
        "\n",
        "# Filter ratings above 0\n",
        "merged_df = merged_df[merged_df['Book-Rating'] > 0]\n",
        "\n",
        "# Filter users aged less than 110\n",
        "merged_df = merged_df[merged_df['Age'] < 110]\n",
        "\n",
        "# Count the number of ratings by each user\n",
        "user_ratings_count = merged_df['User-ID'].value_counts()\n",
        "\n",
        "# Keep only users who have rated 3 or more books\n",
        "valid_users = user_ratings_count[user_ratings_count >= 2].index\n",
        "merged_df = merged_df[merged_df['User-ID'].isin(valid_users)]\n",
        "\n",
        "# Use only a fraction of the dataset\n",
        "merged_df = merged_df.sample(frac=0.01, random_state=42)\n",
        "\n",
        "# Data Splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(merged_df, test_size=0.7, random_state=42)\n",
        "\n",
        "# Checking the transformations and missing values after preprocessing\n",
        "print(\"\\nData after preprocessing:\")\n",
        "print(\"Unique values in 'Year-Of-Publication':\", books_df['Year-Of-Publication'].unique())\n",
        "print(\"\\nMissing values after preprocessing:\")\n",
        "print(\"Users:\", users_df.isnull().sum())\n",
        "print(\"Books:\", books_df.isnull().sum())\n",
        "print(\"Ratings:\", ratings_df.isnull().sum())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqtkaoO73hqn"
      },
      "source": [
        "# **Content Based Filtering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN0ElrkA3pZI"
      },
      "source": [
        "### 1. Weighted rating scores of each book for prediction\n",
        "\n",
        "### NOTE: May not need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL2zDq8M7wob",
        "outputId": "35745a20-fc83-40bf-c50e-117c584655ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Average Rating: 7.665682370662013\n",
            "Minimum ratings required: 3.0\n",
            "           ISBN  Rating_Count  Average_Rating  Weighted_Rating\n",
            "35   0385484518           391            10.0         9.982226\n",
            "36   0446310786           389            10.0         9.982135\n",
            "47   0440206154           365            10.0         9.980970\n",
            "87   1558743669           262            10.0         9.973574\n",
            "91   0345339703           257            10.0         9.973066\n",
            "..          ...           ...             ...              ...\n",
            "461  044011585X            76             2.0         2.215152\n",
            "390  0060188731            91             2.0         2.180820\n",
            "825  3442433495            36             1.0         1.512745\n",
            "317  0679735771           110             1.0         1.176965\n",
            "108  0064407667           230             1.0         1.085824\n",
            "\n",
            "[3193 rows x 4 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/tz/f5wwvbqj0sjgxsr35rx5h1k00000gs/T/ipykernel_4515/1390517382.py:24: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  merged_df['Book-Rating'] = merged_df['Book-Rating_original'].combine_first(merged_df['Book-Rating_mean'])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# Function that computes the weighted rating of each book\n",
        "# We are utilizing the IMDB formula for weighted average ratings\n",
        "def weighted_rating(dataframe, m, C):\n",
        "    v = dataframe['Rating_Count']\n",
        "    R = dataframe['Average_Rating']\n",
        "    return (v / (v + m) * R) + (m / (m + v) * C)\n",
        "\n",
        "# Count the amount of ratings\n",
        "book_rated_count = ratings_df['ISBN'].value_counts().reset_index()\n",
        "book_rated_count.columns = ['ISBN', 'Rating_Count']\n",
        "\n",
        "# print(book_rated_count)\n",
        "global_mean = merged_df['Book-Rating'].mean()\n",
        "\n",
        "# Calculate the average of the ratings for each book\n",
        "average_ratings = merged_df.groupby('ISBN')['Book-Rating'].mean().reset_index()\n",
        "\n",
        "# Merge the book_means DataFrame with the original DataFrame to fill missing ratings in user-book matrix\n",
        "merged_df = pd.merge(merged_df, average_ratings, on='ISBN', how='left', suffixes=('_original', '_mean'))\n",
        "merged_df['Book-Rating'] = merged_df['Book-Rating_original'].combine_first(merged_df['Book-Rating_mean'])\n",
        "merged_df.drop(['Book-Rating_original', 'Book-Rating_mean'], axis=1, inplace=True)\n",
        "\n",
        "average_ratings.columns = ['ISBN', 'Average_Rating']\n",
        "sorted_ratings = average_ratings.sort_values(by='Average_Rating', ascending=False)\n",
        "\n",
        "# Merge the book count and average ratings\n",
        "merged_data = pd.merge(book_rated_count, average_ratings, on='ISBN', how='inner')\n",
        "\n",
        "# Calculate mean of 'Average_Rating' column\n",
        "C = average_ratings['Average_Rating'].mean()\n",
        "print(\"Mean Average Rating:\", C)\n",
        "\n",
        "# Calculate the minimum number of ratings required to be in the chart, m\n",
        "m = book_rated_count['Rating_Count'].quantile(0.80)\n",
        "print(\"Minimum ratings required:\", m)\n",
        "\n",
        "# Filter out all qualified books into a new DataFrame\n",
        "q_books = merged_data.copy().loc[book_rated_count['Rating_Count'] >= m]\n",
        "\n",
        "# Apply weighted rating function to calculate the weighted rating for each book\n",
        "q_books['Weighted_Rating'] = q_books.apply(weighted_rating, axis=1, m=m, C=C)\n",
        "\n",
        "# Sorting the DataFrame by 'Weighted_Rating' in descending order\n",
        "sorted_q_books = q_books.sort_values(by='Weighted_Rating', ascending=False)\n",
        "\n",
        "# Print the result\n",
        "print(sorted_q_books)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6S2pChFMF5n"
      },
      "source": [
        "### 2. Content Based Recommendation using book title and author\n",
        "We will use content based filtering to create part of our recommendation system. We will use book information for this part. The book information includes: Book title and author"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8v30Macn4A2k"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Create content dataframe with only the book title and author\n",
        "content_df = merged_df[['Book-Title', 'Book-Author', 'ISBN']].copy()\n",
        "\n",
        "# Combine the title and author and store in Book-Information column\n",
        "content_df['Book-Information'] = content_df['Book-Title'] + ' ' + content_df['Book-Author']\n",
        "\n",
        "# Drop all duplicate rows based on the 'Book-Information' column\n",
        "content_df = content_df.drop_duplicates(subset='Book-Information')\n",
        "\n",
        "# Reset the index after dropping duplicates\n",
        "content_df = content_df.reset_index(drop=True)\n",
        "\n",
        "# Construct the required TF-IDF matrix for all books information\n",
        "books_tfidf_matrix = tfidf.fit_transform(content_df['Book-Information'])\n",
        "\n",
        "# Calculate cosine similarity of the books matrix\n",
        "similarity = linear_kernel(books_tfidf_matrix, books_tfidf_matrix)\n",
        "\n",
        "def content_based_recommendations(book_title, book_author, top_n, similarity_matrix=similarity, df=content_df):\n",
        "    # Combine title and author for the given book\n",
        "    input_book_info = book_title + ' ' + book_author\n",
        "\n",
        "    # Get the index of the input book\n",
        "    input_book_index = df[df['Book-Information'] == input_book_info].index[0]\n",
        "\n",
        "    # Get the cosine similarity using the precomputed similarity matrix\n",
        "    similarity_scores = similarity_matrix[input_book_index]\n",
        "\n",
        "    # Get the indices of the top-n most similar books\n",
        "    top_indices = similarity_scores.argsort()[-top_n-1:-1]\n",
        "\n",
        "    # Return the top-n most similar books\n",
        "    return df.loc[top_indices, ['ISBN', 'Book-Title', 'Book-Author']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-J0MJWDKrfA",
        "outputId": "d075aeed-fe43-4e98-c77f-d4526a7ee2d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommendations for 'Dating Big Bird' by Laura Zigman (Existing User):\n",
            "            ISBN                                         Book-Title  \\\n",
            "738   0399145672                                        Big Trouble   \n",
            "497   0887330630                         Bird Isle and Take My Face   \n",
            "2204  0345445848  Big Cherry Holler: A Big Stone Gap Novel (Ball...   \n",
            "3042  0385196156                               The Song of the Bird   \n",
            "2394  0385319037                                   Animal Husbandry   \n",
            "\n",
            "           Book-Author  \n",
            "738         Dave Barry  \n",
            "497         Jack Vance  \n",
            "2204  Adriana Trigiani  \n",
            "3042  Anthony De Mello  \n",
            "2394      Laura Zigman  \n"
          ]
        }
      ],
      "source": [
        "NUM_OF_RECOMMENDED_BOOKS = 5\n",
        "\n",
        "# Use the random_state in the sample method\n",
        "random_row = train_data.sample(n=1)\n",
        "\n",
        "# Use recommend system to get a content based recommendation of the top 5 books for the user\n",
        "book_title = random_row['Book-Title'].values[0]\n",
        "book_author = random_row['Book-Author'].values[0]\n",
        "\n",
        "recommendations_existing_user = content_based_recommendations(book_title, book_author, NUM_OF_RECOMMENDED_BOOKS)\n",
        "\n",
        "print(f\"Recommendations for '{book_title}' by {book_author} (Existing User):\")\n",
        "print(recommendations_existing_user)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1Q6QJYezM4q"
      },
      "source": [
        "# **Collaborative Filtering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "gnUcLmcuzM4q",
        "outputId": "11f1dbe8-f990-480b-b6d3-0effd8beea19"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Book-Rating</th>\n",
              "      <th>num_ratings</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISBN</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>044021145X</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1400034779</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0553279912</th>\n",
              "      <td>8.333333</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0802135226</th>\n",
              "      <td>8.500000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0060928336</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0553801929</th>\n",
              "      <td>7.500000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>067976402X</th>\n",
              "      <td>8.500000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0380769557</th>\n",
              "      <td>7.500000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0679745203</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0684874350</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Book-Rating  num_ratings\n",
              "ISBN                                \n",
              "044021145X     9.000000            3\n",
              "1400034779     7.000000            3\n",
              "0553279912     8.333333            3\n",
              "0802135226     8.500000            2\n",
              "0060928336     7.000000            2\n",
              "0553801929     7.500000            2\n",
              "067976402X     8.500000            2\n",
              "0380769557     7.500000            2\n",
              "0679745203     9.000000            2\n",
              "0684874350     7.000000            2"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings = pd.DataFrame(train_data.groupby('ISBN')['Book-Rating'].mean())\n",
        "\n",
        "ratings['num_ratings'] = pd.DataFrame(train_data.groupby('ISBN')['Book-Rating'].count())\n",
        "ratings.head()\n",
        "\n",
        "bookmat = train_data.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating')\n",
        "bookmat.head()\n",
        "\n",
        "ratings.sort_values('num_ratings', ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "IQWJ0mqvzM4r",
        "outputId": "d5d2785f-f1ee-4951-a14f-9d29c6d7db73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters:  {'algorithm': 'auto', 'metric': 'euclidean', 'n_neighbors': 40}\n",
            "Best RMSE:  1.851416997740723\n",
            "Test RMSE:  1.7831008528550152\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a LabelEncoder object\n",
        "isbn_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder to the ISBN column\n",
        "merged_df['ISBN_encoded'] = isbn_encoder.fit_transform(merged_df['ISBN'])\n",
        "test_data['ISBN_encoded'] = isbn_encoder.transform(test_data['ISBN'])\n",
        "\n",
        "# Convert the ISBN column to a numpy array\n",
        "x_train_global_mean = merged_df[['User-ID', 'ISBN_encoded', 'Book-Rating']].to_numpy()\n",
        "x_test = test_data[['User-ID', 'ISBN_encoded']].to_numpy()\n",
        "\n",
        "# Specify parameter grid for KNN\n",
        "param_grid = {\n",
        "    'n_neighbors': [40, 45, 50],\n",
        "    'algorithm': ['auto'],\n",
        "    'metric': ['euclidean', 'manhattan', 'chebyshev'],\n",
        "}\n",
        "\n",
        "# Create KNN model\n",
        "knn_model = KNeighborsRegressor()\n",
        "\n",
        "# Use GridSearchCV to find the best parameters\n",
        "gs = GridSearchCV(knn_model, param_grid, scoring='neg_mean_squared_error', cv=3)\n",
        "try:\n",
        "    gs.fit(x_train_global_mean[:, :-1], x_train_global_mean[:, -1])\n",
        "except ValueError as e:\n",
        "    print(f\"Error during grid search. Error: {e}\")\n",
        "\n",
        "# Print the best parameters and corresponding RMSE\n",
        "print(\"Best Parameters: \", gs.best_params_)\n",
        "print(\"Best RMSE: \", (-gs.best_score_) ** 0.5)\n",
        "\n",
        "# Predict on the test set\n",
        "test_predictions = gs.predict(x_test)\n",
        "\n",
        "# Evaluate the model\n",
        "test_rmse = mean_squared_error(test_data['Book-Rating'], test_predictions) ** 0.5\n",
        "print(\"Test RMSE: \", test_rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0MoaniizM4r",
        "outputId": "e622d683-39ae-4153-f83c-d7d072063e61"
      },
      "outputs": [],
      "source": [
        "def collaborative_recommendations(user_id, book_isbn, isbn_encoder=isbn_encoder, model=gs):\n",
        "    try:\n",
        "        # Encode the ISBN for the given book\n",
        "        book_encoded = isbn_encoder.transform([book_isbn])[0]\n",
        "\n",
        "        # Predict the rating for the given user and book\n",
        "        prediction = model.predict([[user_id, book_encoded]])[0]\n",
        "        return prediction\n",
        "    except ValueError:\n",
        "        print(\"User ID or ISBN not found in dataset.\")\n",
        "        return global_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "STAC9sdKzM4s",
        "outputId": "830079ef-2966-4be9-f862-d948399f98b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted rating for user 175271 and book 0060186976: 7.45\n",
            "Actual rating for user 175271 and book 0060186976: 6\n"
          ]
        }
      ],
      "source": [
        "# Get a random user from the test set\n",
        "user_id = test_data.sample(n=1)['User-ID'].values[0]\n",
        "# get a random book from the test set that the user has rated\n",
        "book_isbn = test_data[test_data['User-ID'] == user_id].sample(n=1)['ISBN'].values[0]\n",
        "\n",
        "predicted_rating = collaborative_recommendations(user_id, book_isbn)\n",
        "\n",
        "print(f\"Predicted rating for user {user_id} and book {book_isbn}: {predicted_rating}\")\n",
        "# Print actual rating for the book\n",
        "print(f\"Actual rating for user {user_id} and book {book_isbn}: {test_data[(test_data['User-ID'] == user_id) & (test_data['ISBN'] == book_isbn)]['Book-Rating'].values[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H7_-5dG7LfW"
      },
      "source": [
        "### **Hybrid Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "d8dvEUXu7K-4",
        "outputId": "d0b6796c-4abe-4fc3-a25d-30e80c5d7556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Randomly Selected Row:\n",
            "      User-ID                                         Book-Title  \\\n",
            "1244    76499  The Kingdom of Matthias/a Story of Sex and Sal...   \n",
            "\n",
            "          Book-Author  \n",
            "1244  Paul E. Johnson  \n",
            "------------------------\n",
            "                                           Book-Title  \\\n",
            "40         Travels With Charley: In Search of America   \n",
            "43  The Man Who Talks to Dogs: The Story of Americ...   \n",
            "21   From the Ground Up : The Story of a First Garden   \n",
            "13                         Animal Farm: A Fairy Story   \n",
            "33                                    Angels: A Novel   \n",
            "46  The Soul of Sex: Cultivating Life As an Act of...   \n",
            "4       Smoked: A True Story About the Kids Next Door   \n",
            "31  The Bitch in the House : 26 Women Tell the Tru...   \n",
            "26  Death of Common Sense : How Law is Suffocating...   \n",
            "41                   The Future Homemakers of America   \n",
            "7        Boy: Tales of Childhood (Puffin Story Books)   \n",
            "8   Lady Cop: True Stories of Police Women in Amer...   \n",
            "49                Paul Harvey's the Rest of the Story   \n",
            "38  Alive : The Story of the Andes Survivors (Avon...   \n",
            "32                               Three Negro Classics   \n",
            "39      America and Americans and Selected Nonfiction   \n",
            "29                                     Oliver's Story   \n",
            "47  The Other Side of the River: A Story of Two To...   \n",
            "1   Gods, Graves, and Scholars: The Story of Archa...   \n",
            "0   A Common Life : The Wedding Story (The Mitford...   \n",
            "9                               Enemies, a love story   \n",
            "14  Driving Mr. Albert: A Trip Across America With...   \n",
            "5   The Parrot Who Owns Me: The Story of a Relatio...   \n",
            "2   The Sisterhood: The True Story of the Women Wh...   \n",
            "16  Apocalypse Pretty Soon: Travels in End-Time Am...   \n",
            "19                                         Le Mariage   \n",
            "42      DIANA: HER TRUE STORY : DIANA: HER TRUE STORY   \n",
            "12     Against the Gods: The Remarkable Story of Risk   \n",
            "36             Blue Highways : A Journey into America   \n",
            "11            The Story of the House of Wooden Santas   \n",
            "37  Sex, Drugs, and Cocoa Puffs : A Low Culture Ma...   \n",
            "34                   My Own Country: A Doctor's Story   \n",
            "25                             The Pact: A Love Story   \n",
            "28  Germs : Biological Weapons and America's Secre...   \n",
            "27  MELATONIN MIRACLE : Nature's Age-Reversing, Se...   \n",
            "45             Sex, Art, and American Culture: Essays   \n",
            "23                                             Fudoki   \n",
            "22  The Millionaire Next Door: The Surprising Secr...   \n",
            "15                       Chantecler - A Story of Love   \n",
            "44  Sex and Rockets: The Occult World of Jack Parsons   \n",
            "48                          Sex: Portraits of Passion   \n",
            "20  The Whiz Kids and the 1950 Pennant (Baseball i...   \n",
            "6    Paul Strand: The World on My Doorstep (Aperture)   \n",
            "10              Oracle Night : A Novel (Auster, Paul)   \n",
            "30        Ciao, America: An Italian Discovers the U.S   \n",
            "18                Read Me a Story (My First Treasury)   \n",
            "35   Nickel and Dimed: On (Not) Getting By in America   \n",
            "17                      Water, Carry Me: A Love Story   \n",
            "3   Internal Bleeding : The Truth Behind America's...   \n",
            "24  Prozac Nation: Young and Depressed in America ...   \n",
            "\n",
            "                Book-Author  Predicted-Rating  \n",
            "40           John Steinbeck             8.225  \n",
            "43             Melinda Roth             8.175  \n",
            "21              Amy Stewart             8.175  \n",
            "13            George Orwell             8.175  \n",
            "33            Denis Johnson             8.150  \n",
            "46             Thomas Moore             8.150  \n",
            "4                 Leon Bing             8.150  \n",
            "31            Cathi Hanauer             8.150  \n",
            "26         Phillip K Howard             8.125  \n",
            "41            Laurie Graham             8.125  \n",
            "7                Roald Dahl             8.125  \n",
            "8             Bryna Taubman             8.125  \n",
            "49             Paul Aurandt             8.100  \n",
            "38          Piers Paul Read             8.075  \n",
            "32         James W. Johnson             8.075  \n",
            "39           John Steinbeck             8.075  \n",
            "29              Erich Segal             8.075  \n",
            "47           Alex Kotlowitz             8.075  \n",
            "1               C. W. Ceram             8.075  \n",
            "0                 Jan Karon             8.075  \n",
            "9     Isaac Bashevis Singer             8.075  \n",
            "14        Michael Paterniti             8.075  \n",
            "5             Joanna Burger             8.075  \n",
            "2              Marcia Cohen             8.075  \n",
            "16               Alex Heard             8.075  \n",
            "19            Diane Johnson             8.050  \n",
            "42            Andrew Morton             8.050  \n",
            "12      Peter L.  Bernstein             8.050  \n",
            "36  William Least Heat-Moon             8.025  \n",
            "11              Kevin Major             8.000  \n",
            "37         Chuck Klosterman             8.000  \n",
            "34              A. Verghese             8.000  \n",
            "25             Jodi Picoult             8.000  \n",
            "28            Judith Miller             8.000  \n",
            "27         Walter Pierpaoli             8.000  \n",
            "45           Camille Paglia             8.000  \n",
            "23              Kij Johnson             8.000  \n",
            "22        Thomas J. Stanley             8.000  \n",
            "15     Victor Thomas Salupo             7.900  \n",
            "44              John Carter             7.900  \n",
            "48            John Williams             7.875  \n",
            "20            Robin Roberts             7.875  \n",
            "6               Paul Strand             7.875  \n",
            "10              Paul Auster             7.875  \n",
            "30         Beppe Severgnini             7.875  \n",
            "18         Brooke Zimmerman             7.875  \n",
            "35       Barbara Ehrenreich             7.875  \n",
            "17             Thomas Moran             7.850  \n",
            "3            Robert Wachter             7.850  \n",
            "24        Elizabeth Wurtzel             7.850  \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Book-Title</th>\n",
              "      <th>Book-Author</th>\n",
              "      <th>Predicted-Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Travels With Charley: In Search of America</td>\n",
              "      <td>John Steinbeck</td>\n",
              "      <td>8.225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>The Man Who Talks to Dogs: The Story of Americ...</td>\n",
              "      <td>Melinda Roth</td>\n",
              "      <td>8.175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>From the Ground Up : The Story of a First Garden</td>\n",
              "      <td>Amy Stewart</td>\n",
              "      <td>8.175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Animal Farm: A Fairy Story</td>\n",
              "      <td>George Orwell</td>\n",
              "      <td>8.175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Angels: A Novel</td>\n",
              "      <td>Denis Johnson</td>\n",
              "      <td>8.150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Book-Title     Book-Author  \\\n",
              "40         Travels With Charley: In Search of America  John Steinbeck   \n",
              "43  The Man Who Talks to Dogs: The Story of Americ...    Melinda Roth   \n",
              "21   From the Ground Up : The Story of a First Garden     Amy Stewart   \n",
              "13                         Animal Farm: A Fairy Story   George Orwell   \n",
              "33                                    Angels: A Novel   Denis Johnson   \n",
              "\n",
              "    Predicted-Rating  \n",
              "40             8.225  \n",
              "43             8.175  \n",
              "21             8.175  \n",
              "13             8.175  \n",
              "33             8.150  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Hybrid Recommendation System\n",
        "\"\"\"\n",
        "Generate hybrid book recommendations for a user.\n",
        "\n",
        "Parameters:\n",
        "- content_row: DataFrame row representing the user and book information.\n",
        "- top_n: Number of top recommendations to return.\n",
        "- collaborative_model: Function for collaborative filtering recommendations.\n",
        "- content_model: Function for content-based recommendations.\n",
        "\n",
        "Returns:\n",
        "- DataFrame containing the top hybrid book recommendations.\n",
        "\"\"\"\n",
        "def hybrid_recommendations(content_row, top_n, collaborative_model=collaborative_recommendations, content_model=content_based_recommendations):\n",
        "    # Extract data from row\n",
        "    book_title = content_row['Book-Title'].values[0]\n",
        "    book_author = content_row['Book-Author'].values[0]\n",
        "    user_id = content_row['User-ID'].values[0]\n",
        "\n",
        "    # Get content-based recommendations for the user\n",
        "    book_recommendations = content_based_recommendations(book_title, book_author, top_n)\n",
        "\n",
        "    # Create an empty DataFrame to store the predicted ratings\n",
        "    predictions_df = pd.DataFrame()\n",
        "\n",
        "    # Iterate through content-based recommendations\n",
        "    for index, row in book_recommendations.iterrows():\n",
        "        book_title = row['Book-Title']\n",
        "        book_author = row['Book-Author']\n",
        "        book_isbn = row['ISBN']\n",
        "\n",
        "        # Predict the rating using collaborative filtering\n",
        "        predicted_rating = collaborative_recommendations(user_id, book_isbn)\n",
        "\n",
        "        # Append the results to the DataFrame\n",
        "        predictions_df = pd.concat([predictions_df, pd.DataFrame({'Book-Title': [book_title], 'Book-Author': [book_author], 'Predicted-Rating': [predicted_rating]})], ignore_index=True)\n",
        "\n",
        "    # Sort the DataFrame based on predicted ratings\n",
        "    predictions_df = predictions_df.sort_values(by='Predicted-Rating', ascending=False)\n",
        "    print('------------------------')\n",
        "    print(predictions_df)\n",
        "\n",
        "    # Get the top 5 books\n",
        "    top_hybrid_books = predictions_df.head(5)\n",
        "\n",
        "    return top_hybrid_books\n",
        "\n",
        "# Assuming you have a DataFrame named test_data\n",
        "random_row = merged_df.sample(n=1)  # Use a specific random_state for reproducibility\n",
        "\n",
        "# Display the randomly selected row\n",
        "print(\"Randomly Selected Row:\")\n",
        "print(random_row[['User-ID', 'Book-Title', 'Book-Author']])\n",
        "\n",
        "hybrid_recommendations(random_row, 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z975ITU63ntV"
      },
      "source": [
        "# OTHER (DELETE BEFORE SUBMIT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PGuD5lcAuFwu",
        "outputId": "ef280847-b1d4-47d4-b14c-80da68fba253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ISBN     0007154607  0020209851  0020518609  0020795904  006000438X  \\\n",
            "User-ID                                                               \n",
            "2276              0           0           0           0           0   \n",
            "6242              0           0           0           0           0   \n",
            "8067              0           0           0           0           0   \n",
            "11676             0           0           0           0           0   \n",
            "12100             0           0           0           0           0   \n",
            "\n",
            "ISBN     0060006293  0060086386  0060089539  0060109955  0060159383  ...  \\\n",
            "User-ID                                                              ...   \n",
            "2276              0           0           0           0           0  ...   \n",
            "6242              0           0           0           0           0  ...   \n",
            "8067              0           0           0           0           0  ...   \n",
            "11676             0           0           0           0           9  ...   \n",
            "12100             0           0           0           0           0  ...   \n",
            "\n",
            "ISBN     189206524X  1903845882  2266078720  2266125354  2850250481  \\\n",
            "User-ID                                                               \n",
            "2276              0           0           0           0           0   \n",
            "6242              0           0           0           0           0   \n",
            "8067              0           0           0           0           0   \n",
            "11676             0           0           0           8           0   \n",
            "12100             0           0           0           0           0   \n",
            "\n",
            "ISBN     843501634X  8466300473  8475960715  8483102161  9502802861  \n",
            "User-ID                                                              \n",
            "2276              0           0           0           0           0  \n",
            "6242              0           0           0           0           0  \n",
            "8067              0           0           0           0           0  \n",
            "11676             0           8           8           7           0  \n",
            "12100             0           0           0           0           0  \n",
            "\n",
            "[5 rows x 804 columns]\n",
            "        User-ID        ISBN  Book-Rating  \\\n",
            "184873    78973  0671039725            8   \n",
            "4137      98391  1551667487            9   \n",
            "743528     6242  0684865726            5   \n",
            "318821   156150  0380715430            8   \n",
            "9889     115435  0156106809            9   \n",
            "...         ...         ...          ...   \n",
            "30478     11676  044100508X            8   \n",
            "422810   189334  0395080487           10   \n",
            "68805     13552  0515128554            7   \n",
            "44186    158295  0451192311            6   \n",
            "420119    52853  0060526203            6   \n",
            "\n",
            "                                               Book-Title       Book-Author  \\\n",
            "184873                                             Carrie      Stephen King   \n",
            "4137                                         Return To Me   Rosemary Rogers   \n",
            "743528           True At First Light : A Fictional Memoir  Ernest Hemingway   \n",
            "318821                                  The Mother Tongue       Bill Bryson   \n",
            "9889                               The Baron in the Trees     Italo Calvino   \n",
            "...                                                   ...               ...   \n",
            "30478               The Pearls of Lutra (Redwall, Book 9)     Brian Jacques   \n",
            "422810  The natural way to draw: A working plan for ar...  Kimon Nicolaides   \n",
            "68805                    Heart of the Sea (Irish Trilogy)      Nora Roberts   \n",
            "44186   Eat Drink and Be Wary: A Pennsylvania Dutch My...       Tamar Myers   \n",
            "420119                                      Kiss Me Quick    Margaret Moore   \n",
            "\n",
            "        Year-Of-Publication            Publisher  \\\n",
            "184873               2002.0               Pocket   \n",
            "4137                 2003.0                 Mira   \n",
            "743528               2000.0             Scribner   \n",
            "318821               1991.0            Perennial   \n",
            "9889                 1977.0             Harcourt   \n",
            "...                     ...                  ...   \n",
            "30478                1998.0            Ace Books   \n",
            "422810               1975.0  Houghton Mifflin Co   \n",
            "68805                2000.0           Jove Books   \n",
            "44186                1998.0          Signet Book   \n",
            "420119               2003.0                 Avon   \n",
            "\n",
            "                                              Image-URL-S  \\\n",
            "184873  http://images.amazon.com/images/P/0671039725.0...   \n",
            "4137    http://images.amazon.com/images/P/1551667487.0...   \n",
            "743528  http://images.amazon.com/images/P/0684865726.0...   \n",
            "318821  http://images.amazon.com/images/P/0380715430.0...   \n",
            "9889    http://images.amazon.com/images/P/0156106809.0...   \n",
            "...                                                   ...   \n",
            "30478   http://images.amazon.com/images/P/044100508X.0...   \n",
            "422810  http://images.amazon.com/images/P/0395080487.0...   \n",
            "68805   http://images.amazon.com/images/P/0515128554.0...   \n",
            "44186   http://images.amazon.com/images/P/0451192311.0...   \n",
            "420119  http://images.amazon.com/images/P/0060526203.0...   \n",
            "\n",
            "                                              Image-URL-M  \\\n",
            "184873  http://images.amazon.com/images/P/0671039725.0...   \n",
            "4137    http://images.amazon.com/images/P/1551667487.0...   \n",
            "743528  http://images.amazon.com/images/P/0684865726.0...   \n",
            "318821  http://images.amazon.com/images/P/0380715430.0...   \n",
            "9889    http://images.amazon.com/images/P/0156106809.0...   \n",
            "...                                                   ...   \n",
            "30478   http://images.amazon.com/images/P/044100508X.0...   \n",
            "422810  http://images.amazon.com/images/P/0395080487.0...   \n",
            "68805   http://images.amazon.com/images/P/0515128554.0...   \n",
            "44186   http://images.amazon.com/images/P/0451192311.0...   \n",
            "420119  http://images.amazon.com/images/P/0060526203.0...   \n",
            "\n",
            "                                              Image-URL-L  \\\n",
            "184873  http://images.amazon.com/images/P/0671039725.0...   \n",
            "4137    http://images.amazon.com/images/P/1551667487.0...   \n",
            "743528  http://images.amazon.com/images/P/0684865726.0...   \n",
            "318821  http://images.amazon.com/images/P/0380715430.0...   \n",
            "9889    http://images.amazon.com/images/P/0156106809.0...   \n",
            "...                                                   ...   \n",
            "30478   http://images.amazon.com/images/P/044100508X.0...   \n",
            "422810  http://images.amazon.com/images/P/0395080487.0...   \n",
            "68805   http://images.amazon.com/images/P/0515128554.0...   \n",
            "44186   http://images.amazon.com/images/P/0451192311.0...   \n",
            "420119  http://images.amazon.com/images/P/0060526203.0...   \n",
            "\n",
            "                          Location   Age  \n",
            "184873   amadora, lisboa, portugal  29.0  \n",
            "4137          morrow, georgia, usa  52.0  \n",
            "743528    calgary, alberta, canada  32.0  \n",
            "318821     howell, new jersey, usa  36.0  \n",
            "9889         cincinnati, ohio, usa  30.0  \n",
            "...                            ...   ...  \n",
            "30478                n/a, n/a, n/a  32.0  \n",
            "422810     ottawa, ontario, canada  49.0  \n",
            "68805      cordova, tennessee, usa  32.0  \n",
            "44186         cleveland, ohio, usa  32.0  \n",
            "420119  yuba city, california, usa  61.0  \n",
            "\n",
            "[812 rows x 12 columns]\n",
            "ISBN     0007154607  0020209851  0020518609  0020795904  006000438X  \\\n",
            "User-ID                                                               \n",
            "2276              0           0           0           0           0   \n",
            "6242              0           0           0           0           0   \n",
            "8067              0           0           0           0           0   \n",
            "11676             0           0           0           0           0   \n",
            "12100             0           0           0           0           0   \n",
            "...             ...         ...         ...         ...         ...   \n",
            "264031            0           0           0           0           0   \n",
            "265313            0           0           0           0           0   \n",
            "269890            0           0           0           0           0   \n",
            "270713            0           0           0           0           0   \n",
            "271195            0           0           0           0           0   \n",
            "\n",
            "ISBN     0060006293  0060086386  0060089539  0060109955  0060159383  ...  \\\n",
            "User-ID                                                              ...   \n",
            "2276              0           0           0           0           0  ...   \n",
            "6242              0           0           0           0           0  ...   \n",
            "8067              0           0           0           0           0  ...   \n",
            "11676             0           0           0           0           9  ...   \n",
            "12100             0           0           0           0           0  ...   \n",
            "...             ...         ...         ...         ...         ...  ...   \n",
            "264031            0           0           0           0           0  ...   \n",
            "265313            0           0           0           0           0  ...   \n",
            "269890            0           0           0           0           0  ...   \n",
            "270713            0           0           0           0           0  ...   \n",
            "271195            0           0           0           0           0  ...   \n",
            "\n",
            "ISBN     189206524X  1903845882  2266078720  2266125354  2850250481  \\\n",
            "User-ID                                                               \n",
            "2276              0           0           0           0           0   \n",
            "6242              0           0           0           0           0   \n",
            "8067              0           0           0           0           0   \n",
            "11676             0           0           0           8           0   \n",
            "12100             0           0           0           0           0   \n",
            "...             ...         ...         ...         ...         ...   \n",
            "264031            0           0           0           0           0   \n",
            "265313            0           0           0           0           7   \n",
            "269890            0           0           0           0           0   \n",
            "270713            0           0           0           0           0   \n",
            "271195            0           0           0           0           0   \n",
            "\n",
            "ISBN     843501634X  8466300473  8475960715  8483102161  9502802861  \n",
            "User-ID                                                              \n",
            "2276              0           0           0           0           0  \n",
            "6242              0           0           0           0           0  \n",
            "8067              0           0           0           0           0  \n",
            "11676             0           8           8           7           0  \n",
            "12100             0           0           0           0           0  \n",
            "...             ...         ...         ...         ...         ...  \n",
            "264031            0           0           0           0           0  \n",
            "265313            0           0           0           0           0  \n",
            "269890            0           0           0           0           0  \n",
            "270713            0           0           0           0           0  \n",
            "271195            0           0           0           0           0  \n",
            "\n",
            "[158 rows x 804 columns]\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 14559",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-39a1fd1c3bce>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mtarget_user_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m14559\u001b[0m  \u001b[0;31m# Replace with the actual user ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mtop_recommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollaborative_filtering_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_user_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_item_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Display the top N recommended books\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-39a1fd1c3bce>\u001b[0m in \u001b[0;36mcollaborative_filtering_recommendations\u001b[0;34m(user_id, user_item_matrix, user_similarity, N)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcollaborative_filtering_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_item_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Get the target user's ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtarget_user_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_item_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Calculate similarity scores between the target user and all other users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1310\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;31m# GH#5567 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4054\u001b[0m                     \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4055\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4056\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4058\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 14559"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Create a user-item matrix\n",
        "user_item_matrix = pd.pivot_table(content_df, values='Book-Rating', index='User-ID', columns='ISBN', fill_value=0)\n",
        "\n",
        "print(content_df)\n",
        "print(user_item_matrix)\n",
        "# Calculate user-user cosine similarity\n",
        "user_similarity = cosine_similarity(user_item_matrix)\n",
        "\n",
        "# Function to get top N recommendations for a user using collaborative filtering\n",
        "def collaborative_filtering_recommendations(user_id, user_item_matrix, user_similarity, N=5):\n",
        "    # Get the target user's ratings\n",
        "    target_user_ratings = user_item_matrix.loc[user_id].values.reshape(1, -1)\n",
        "\n",
        "    # Calculate similarity scores between the target user and all other users\n",
        "    sim_scores = cosine_similarity(target_user_ratings, user_item_matrix.values)\n",
        "\n",
        "\n",
        "    # Get the indices of users with highest similarity scores\n",
        "    similar_users = np.argsort(sim_scores[0])[::-1][1:N+1]\n",
        "\n",
        "    print(similar_users)\n",
        "    # Get books that the target user hasn't rated\n",
        "    unrated_books = user_item_matrix.columns[user_item_matrix.loc[user_id] == 0]\n",
        "    print(unrated_books)\n",
        "\n",
        "    # Convert unrated_books to a list\n",
        "    unrated_books = unrated_books.tolist()\n",
        "\n",
        "    print(\"user_item_matrix shape:\", user_item_matrix)\n",
        "\n",
        "    # Get the average rating of each unrated book from similar users\n",
        "    average_ratings = np.mean(user_item_matrix.loc[similar_users, unrated_books], axis=0)\n",
        "\n",
        "    # Get top N recommendations\n",
        "    top_n_books = unrated_books[np.argsort(average_ratings)[::-1][:N]]\n",
        "\n",
        "    return top_n_books\n",
        "\n",
        "# Example usage\n",
        "target_user_id = 14559  # Replace with the actual user ID\n",
        "top_recommendations = collaborative_filtering_recommendations(target_user_id, user_item_matrix, user_similarity, N=5)\n",
        "\n",
        "# Display the top N recommended books\n",
        "recommended_books_info = books_df[books_df['ISBN'].isin(top_recommendations)]\n",
        "print(\"Top N Recommended Books:\")\n",
        "print(recommended_books_info[['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "55pvZjwMOQDF",
        "outputId": "caff33be-0263-4efe-a29b-e55150f27a7a"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-9d4083447471>\u001b[0m in \u001b[0;36m<cell line: 146>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0mtop_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# Number of recommendations to return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m \u001b[0mrecommended_books\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent_based_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooks_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Based Recommendations:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommended_books\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-9d4083447471>\u001b[0m in \u001b[0;36mcontent_based_recommendations\u001b[0;34m(books_df, ratings_df, user_id, threshold, top_n)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Get the similarity between all books and the books that user recommended\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mcontent_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_tfidf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbooks_tfidf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_similarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1391\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    178\u001b[0m             )\n\u001b[1;32m    179\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;34m\"Incompatible dimension for X and Y matrices: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;34m\"X.shape[1] == %d while Y.shape[1] == %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 26 while Y.shape[1] == 387830"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Collaborative Filtering based on users' age\n",
        "# def collaborative_filtering(user_age, train_data, users_df):\n",
        "#     # Filter users based on age\n",
        "#     filtered_users = users_df[users_df['Age'] == user_age]\n",
        "\n",
        "#     # Filter training data based on selected users and non-zero ratings\n",
        "#     filtered_train_data = train_data[(train_data['User-ID'].isin(filtered_users['User-ID'])) & (train_data['Book-Rating'] != 0)]\n",
        "\n",
        "#     # Create a user-item matrix for collaborative filtering\n",
        "#     user_item_matrix = filtered_train_data.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating')\n",
        "#     user_item_matrix = user_item_matrix.fillna(0)\n",
        "\n",
        "#     print(user_item_matrix)\n",
        "#     # Calculate cosine similarity between users\n",
        "#     cosine_sim_users = cosine_similarity(user_item_matrix, user_item_matrix)\n",
        "\n",
        "#     return cosine_sim_users\n",
        "\n",
        "# Content-Based Filtering based on book ratings\n",
        "# def content_based_filtering(train_data, books_df):\n",
        "#     # Get the top N books with the highest average ratings\n",
        "#     # top_books = train_data.groupby('ISBN')['Book-Rating'].mean().reset_index()\n",
        "#     # top_books = top_books.sort_values(by='Book-Rating', ascending=False)\n",
        "\n",
        "#     # print(top_books)\n",
        "#     # # Merge with books_df to get additional book information\n",
        "#     # top_books = pd.merge(top_books, books_df, on='ISBN')\n",
        "\n",
        "#     # Create a TF-IDF vectorizer for book titles\n",
        "#     tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "#     tfidf_matrix = tfidf_vectorizer.fit_transform(train_data['Book-Rating'])\n",
        "\n",
        "#     print(tfidf_matrix)\n",
        "\n",
        "#     # # Apply Truncated SVD for dimensionality reduction\n",
        "#     # svd = TruncatedSVD(n_components=100)\n",
        "#     # tfidf_matrix_reduced = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "#     # # Calculate the cosine similarity between book titles\n",
        "#     # cosine_sim_books = cosine_similarity(tfidf_matrix_reduced, tfidf_matrix_reduced)\n",
        "#     # print(cosine_sim_books)\n",
        "#     # return cosine_sim_books\n",
        "\n",
        "\n",
        "# def jaccard_similarity(content_matrix):\n",
        "#     # Convert the sparse matrix to a dense matrix\n",
        "#     dense_content_matrix = content_matrix.toarray()\n",
        "\n",
        "#     # Compute Jaccard similarity using pairwise_distances with metric='jaccard'\n",
        "#     jaccard_sim = 1 - pairwise_distances(dense_content_matrix, metric='jaccard')\n",
        "#     return normalize(jaccard_sim, axis=1, norm='l1')  # Normalize the similarity scores\n",
        "\n",
        "# def content_based_filtering(content_df):\n",
        "#     # Sort by ratings and select the top 10,000 rows\n",
        "#     print(content_df)\n",
        "#     books_df = content_df[['Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Book-Rating']]\n",
        "\n",
        "#     # Puts all features in a string\n",
        "#     books_df['Content'] = books_df.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
        "\n",
        "#     print('--------')\n",
        "#     print(books_df)\n",
        "\n",
        "#     tfidf_vectorizer = TfidfVectorizer()\n",
        "#     content_matrix = tfidf_vectorizer.fit_transform(books_df['Content'])\n",
        "\n",
        "#     content_similarity = cosine_similarity(content_matrix, content_matrix)\n",
        "\n",
        "#     return books_df, content_similarity, tfidf_vectorizer\n",
        "\n",
        "# # Example usage\n",
        "# books_df = pd.read_csv('Books.csv')  # Load books data\n",
        "# content_df, content_similarity, tfidf_vectorizer = content_based_filtering(books_df, top_n=10000)\n",
        "\n",
        "\n",
        "# # Hybrid Recommender System\n",
        "# def hybrid_recommender(user_age, user_id, train_data, books_df, users_df):\n",
        "#     # Collaborative Filtering\n",
        "#     # collaborative_results = collaborative_filtering(user_age, train_data, users_df)\n",
        "\n",
        "#     # Content-Based Filtering\n",
        "#     content_based_results = content_based_filtering(train_data)\n",
        "#     # # Combine the results using a weighted sum\n",
        "#     # # Note: Here, we use the mean rating from collaborative filtering\n",
        "#     # # and the cosine similarity values from content-based filtering\n",
        "#     # collaborative_results_df = pd.DataFrame(collaborative_results)\n",
        "#     # collaborative_results_df = collaborative_results_df.fillna(0)\n",
        "\n",
        "#     # hybrid_results = pd.DataFrame(index=train_data['User-ID'], columns=train_data['ISBN'])\n",
        "#     # hybrid_results['Hybrid-Score'] = (0.5 * collaborative_results_df.values +\n",
        "#     #                                    0.5 * content_based_results.loc[collaborative_results_df.index, collaborative_results_df.columns].fillna(0))\n",
        "\n",
        "#     # # Sort the results by Hybrid-Score in descending order\n",
        "#     # recommended_books = hybrid_results.unstack().reset_index(name='Hybrid-Score')\n",
        "#     # user_rated_books = train_data[train_data['User-ID'] == user_id]['ISBN']\n",
        "#     # recommended_books = recommended_books[~recommended_books['ISBN'].isin(user_rated_books)]\n",
        "\n",
        "#     # return recommended_books[['ISBN', 'Hybrid-Score']].nlargest(5, 'Hybrid-Score')\n",
        "#     return\n",
        "\n",
        "def content_based_recommendations(books_df, ratings_df, user_id, threshold=5, top_n=10):\n",
        "    # Filter ratings data for the user and ratings above the threshold\n",
        "    user_ratings = ratings_df[(ratings_df['User-ID'] == user_id)]\n",
        "\n",
        "    # Get the ISBNs of positively rated books by the user\n",
        "    positively_rated_isbns = user_ratings['ISBN'].unique()\n",
        "\n",
        "    # Filter content data for positively rated books\n",
        "    positively_rated_books_df = books_df[books_df['ISBN'].isin(positively_rated_isbns)].drop('ISBN', axis=1)\n",
        "\n",
        "    # Drop ISBN from books as we will not use that to compare\n",
        "    all_books = books_df.drop('ISBN', axis=1)\n",
        "\n",
        "    # Create the 'Content' column without including the 'ISBN'; this will create a string of all the info about that book\n",
        "    positively_rated_books_df['Content'] = positively_rated_books_df.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
        "    all_books['Content'] = all_books.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
        "\n",
        "    # Apply content-based filtering to recommend similar books\n",
        "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    content_tfidf_matrix = tfidf_vectorizer.fit_transform(positively_rated_books_df['Content'])\n",
        "    books_tfidf_matrix = tfidf_vectorizer.fit_transform(all_books['Content'])\n",
        "\n",
        "    # Get the similarity between all books and the books that user recommended\n",
        "    content_similarity = cosine_similarity(content_tfidf_matrix, books_tfidf_matrix)\n",
        "\n",
        "    print(content_similarity)\n",
        "\n",
        "    # Identify books similar to the positively rated ones\n",
        "    similar_books_indices = content_similarity.argsort(axis=1)[:, ::-1][:, :top_n]\n",
        "    similar_books_info = positively_rated_books_df.iloc[similar_books_indices.flatten()]\n",
        "\n",
        "    return similar_books_info\n",
        "\n",
        "# Example usage\n",
        "user_id = 276729  # Replace with the actual user ID\n",
        "threshold = 5  # Ratings above this threshold will be considered\n",
        "top_n = 10  # Number of recommendations to return\n",
        "\n",
        "recommended_books = content_based_recommendations(books_df, ratings_df, user_id, threshold, top_n)\n",
        "print(\"Content-Based Recommendations:\", recommended_books)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qg1t5VTTUA7Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cN0ElrkA3pZI",
        "z975ITU63ntV"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.11.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "054c096e4d4b57417bb781656d4f5218b0e3c2d49c7047d1ff7347fb636be8e8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
