{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "va5H-Oe6OPF7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff4UOlhiOPF-",
        "outputId": "48b38123-a7ac-4937-ec6e-b53820ed4cf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-fc4b50aeeb10>:10: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  books_df = pd.read_csv(books_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data after preprocessing:\n",
            "Unique values in 'Year-Of-Publication': [2002. 2001. 1991. 1999. 2000. 1993. 1996. 1988. 2004. 1998. 1994. 2003.\n",
            " 1997. 1983. 1979. 1995. 1982. 1985. 1992. 1986. 1978. 1980. 1952. 1987.\n",
            " 1990. 1981. 1989. 1984.    0. 1968. 1961. 1958. 1974. 1976. 1971. 1977.\n",
            " 1975. 1965. 1941. 1970. 1962. 1973. 1972. 1960. 1966. 1920. 1956. 1959.\n",
            " 1953. 1951. 1942. 1963. 1964. 1969. 1954. 1950. 1967. 2005. 1957. 1940.\n",
            " 1937. 1955. 1946. 1936. 1930. 2011. 1925. 1948. 1943. 1947. 1945. 1923.\n",
            " 2020. 1939. 1926. 1938. 2030. 1911. 1904. 1949. 1932. 1928. 1929. 1927.\n",
            " 1931. 1914. 2050. 1934. 1910. 1933. 1902. 1924. 1921. 1900. 2038. 2026.\n",
            " 1944. 1917. 1901. 2010. 1908. 1906. 1935. 1806. 2021. 2012. 2006. 1909.\n",
            " 2008. 1378. 1919. 1922. 1897. 2024. 1376. 2037.]\n",
            "\n",
            "Missing values after preprocessing:\n",
            "Users: User-ID     0\n",
            "Location    0\n",
            "Age         0\n",
            "dtype: int64\n",
            "Books: ISBN                   0\n",
            "Book-Title             0\n",
            "Book-Author            0\n",
            "Year-Of-Publication    0\n",
            "Publisher              0\n",
            "Image-URL-S            0\n",
            "Image-URL-M            0\n",
            "Image-URL-L            3\n",
            "dtype: int64\n",
            "Ratings: User-ID        0\n",
            "ISBN           0\n",
            "Book-Rating    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#DATA PRECPROCESSING-----------------------------------------------------------------------------------------------\n",
        "\n",
        "# File paths\n",
        "users_file = 'Users.csv'\n",
        "books_file = 'Books.csv'\n",
        "ratings_file = 'Ratings.csv'\n",
        "\n",
        "# Load the datasets\n",
        "users_df = pd.read_csv(users_file)\n",
        "books_df = pd.read_csv(books_file)\n",
        "ratings_df = pd.read_csv(ratings_file)\n",
        "\n",
        "# Users Data Preprocessing\n",
        "# Handle missing values in 'Age' and 'Location'\n",
        "users_df['Age'].fillna(users_df['Age'].median(), inplace=True)\n",
        "users_df['Location'].fillna('Unknown', inplace=True)\n",
        "\n",
        "\n",
        "# Books Data Preprocessing\n",
        "# Convert 'Year-Of-Publication' to numeric and handle non-numeric values\n",
        "books_df['Year-Of-Publication'] = pd.to_numeric(books_df['Year-Of-Publication'], errors='coerce')\n",
        "books_df['Year-Of-Publication'].fillna(books_df['Year-Of-Publication'].median(), inplace=True)\n",
        "# Handle missing values in 'Book-Author' and 'Publisher'\n",
        "books_df['Book-Author'].fillna('Unknown', inplace=True)\n",
        "books_df['Publisher'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Ratings Data Preprocessing\n",
        "# Merge 'Ratings' with 'Books' to filter out books not in the 'Books' dataset\n",
        "ratings_df = ratings_df[ratings_df['ISBN'].isin(books_df['ISBN'])]\n",
        "\n",
        "# Data Splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(ratings_df, test_size=0.9, random_state=42)\n",
        "\n",
        "# Export Processed Data\n",
        "train_data.to_csv('train_data.csv', index=False)\n",
        "test_data.to_csv('test_data.csv', index=False)\n",
        "\n",
        "# Checking the transformations and missing values after preprocessing\n",
        "print(\"\\nData after preprocessing:\")\n",
        "print(\"Unique values in 'Year-Of-Publication':\", books_df['Year-Of-Publication'].unique())\n",
        "print(\"\\nMissing values after preprocessing:\")\n",
        "print(\"Users:\", users_df.isnull().sum())\n",
        "print(\"Books:\", books_df.isnull().sum())\n",
        "print(\"Ratings:\", ratings_df.isnull().sum())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the preprocessed data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Collaborative Filtering based on users' age and location\n",
        "def collaborative_filtering(user_age, user_location, train_data):\n",
        "    # Filter users based on age and location\n",
        "    filtered_users = users_df[(users_df['Age'] == user_age) & (users_df['Location'] == user_location)]\n",
        "\n",
        "    # Filter training data based on selected users\n",
        "    filtered_train_data = train_data[train_data['User-ID'].isin(filtered_users['User-ID'])]\n",
        "\n",
        "    # Group by book ISBN and calculate the mean rating\n",
        "    book_ratings = filtered_train_data.groupby('ISBN')['Book-Rating'].mean().reset_index()\n",
        "\n",
        "    return book_ratings\n",
        "\n",
        "# Content-Based Filtering based on book ratings\n",
        "def content_based_filtering(train_data, books_df):\n",
        "    # Merge training data with book information\n",
        "    merged_data = pd.merge(train_data, books_df, on='ISBN')\n",
        "\n",
        "    # Group by book ISBN and calculate the mean rating\n",
        "    book_ratings = merged_data.groupby('ISBN')['Book-Rating'].mean().reset_index()\n",
        "\n",
        "    # Merge with books_df to get additional book information\n",
        "    book_data = pd.merge(book_ratings, books_df, on='ISBN')\n",
        "\n",
        "    # Create a TF-IDF vectorizer for book titles\n",
        "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(book_data['Book-Title'])\n",
        "\n",
        "    # Calculate the cosine similarity between book titles\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    return cosine_sim\n",
        "\n",
        "# Hybrid Recommender System\n",
        "def hybrid_recommender(user_age, user_location, user_id, train_data, books_df):\n",
        "    # Collaborative Filtering\n",
        "    collaborative_results = collaborative_filtering(user_age, user_location, train_data)\n",
        "\n",
        "    # Content-Based Filtering\n",
        "    content_based_results = content_based_filtering(train_data, books_df)\n",
        "\n",
        "    # Combine the results using a weighted average or any other method\n",
        "    # For simplicity, we will use the mean rating from collaborative filtering\n",
        "    # and the mean rating from content-based filtering\n",
        "    hybrid_results = pd.merge(collaborative_results, content_based_results, on='ISBN')\n",
        "    hybrid_results['Hybrid-Score'] = (hybrid_results['Book-Rating_x'] + hybrid_results['Book-Rating_y']) / 2\n",
        "\n",
        "    # Sort the results by Hybrid-Score in descending order\n",
        "    recommended_books = hybrid_results.sort_values(by='Hybrid-Score', ascending=False)\n",
        "\n",
        "    # Exclude books that the user has already rated\n",
        "    user_rated_books = train_data[train_data['User-ID'] == user_id]['ISBN']\n",
        "    recommended_books = recommended_books[~recommended_books['ISBN'].isin(user_rated_books)]\n",
        "\n",
        "    return recommended_books\n",
        "\n",
        "# Example of using the hybrid recommender system\n",
        "user_id = 123  # Replace with the actual user ID\n",
        "user_age = 25  # Replace with the user's age\n",
        "user_location = 'New York'  # Replace with the user's location\n",
        "\n",
        "recommendations = hybrid_recommender(user_age, user_location, user_id, train_data, books_df)\n",
        "\n",
        "# Display the top N recommended books\n",
        "top_n = 10\n",
        "print(f\"Top {top_n} Recommended Books:\")\n",
        "print(recommendations.head(top_n))"
      ],
      "metadata": {
        "id": "55pvZjwMOQDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qg1t5VTTUA7Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}