{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "va5H-Oe6OPF7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff4UOlhiOPF-",
        "outputId": "95aebb07-6353-4829-d0c7-4c2a6829c97e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-97be1df8033e>:10: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  books_df = pd.read_csv(books_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data after preprocessing:\n",
            "Unique values in 'Year-Of-Publication': [2002. 2001. 1991. 1999. 2000. 1993. 1996. 1988. 2004. 1998. 1994. 2003.\n",
            " 1997. 1983. 1979. 1995. 1982. 1985. 1992. 1986. 1978. 1980. 1952. 1987.\n",
            " 1990. 1981. 1989. 1984.    0. 1968. 1961. 1958. 1974. 1976. 1971. 1977.\n",
            " 1975. 1965. 1941. 1970. 1962. 1973. 1972. 1960. 1966. 1920. 1956. 1959.\n",
            " 1953. 1951. 1942. 1963. 1964. 1969. 1954. 1950. 1967. 2005. 1957. 1940.\n",
            " 1937. 1955. 1946. 1936. 1930. 2011. 1925. 1948. 1943. 1947. 1945. 1923.\n",
            " 2020. 1939. 1926. 1938. 2030. 1911. 1904. 1949. 1932. 1928. 1929. 1927.\n",
            " 1931. 1914. 2050. 1934. 1910. 1933. 1902. 1924. 1921. 1900. 2038. 2026.\n",
            " 1944. 1917. 1901. 2010. 1908. 1906. 1935. 1806. 2021. 2012. 2006. 1909.\n",
            " 2008. 1378. 1919. 1922. 1897. 2024. 1376. 2037.]\n",
            "\n",
            "Missing values after preprocessing:\n",
            "Users: User-ID     0\n",
            "Location    0\n",
            "Age         0\n",
            "dtype: int64\n",
            "Books: ISBN                   0\n",
            "Book-Title             0\n",
            "Book-Author            0\n",
            "Year-Of-Publication    0\n",
            "Publisher              0\n",
            "dtype: int64\n",
            "Ratings: User-ID        0\n",
            "ISBN           0\n",
            "Book-Rating    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#DATA PRECPROCESSING-----------------------------------------------------------------------------------------------\n",
        "\n",
        "# File paths\n",
        "users_file = 'Users.csv'\n",
        "books_file = 'Books.csv'\n",
        "ratings_file = 'Ratings.csv'\n",
        "\n",
        "# Load the datasets\n",
        "users_df = pd.read_csv(users_file)\n",
        "books_df = pd.read_csv(books_file)\n",
        "ratings_df = pd.read_csv(ratings_file)\n",
        "\n",
        "# Users Data Preprocessing\n",
        "# Handle missing values in 'Age' and 'Location'\n",
        "users_df['Age'].fillna(users_df['Age'].median(), inplace=True)\n",
        "users_df['Location'].fillna('Unknown', inplace=True)\n",
        "\n",
        "\n",
        "# Books Data Preprocessing\n",
        "# Convert 'Year-Of-Publication' to numeric and handle non-numeric values\n",
        "books_df['Year-Of-Publication'] = pd.to_numeric(books_df['Year-Of-Publication'], errors='coerce')\n",
        "books_df['Year-Of-Publication'].fillna(books_df['Year-Of-Publication'].median(), inplace=True)\n",
        "# Handle missing values in 'Book-Author' and 'Publisher'\n",
        "books_df['Book-Author'].fillna('Unknown', inplace=True)\n",
        "books_df['Publisher'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Drop the url columns as we will not be using them\n",
        "books_df.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis=1, inplace=True)\n",
        "\n",
        "# Ratings Data Preprocessing\n",
        "# Merge 'Ratings' with 'Books' to filter out books not in the 'Books' dataset\n",
        "ratings_df = ratings_df[ratings_df['ISBN'].isin(books_df['ISBN'])]\n",
        "\n",
        "# Merge books_df, users_df, and ratings_df\n",
        "merged_df = pd.merge(ratings_df, books_df, on='ISBN', how='inner')\n",
        "merged_df = pd.merge(merged_df, users_df, on='User-ID', how='inner')\n",
        "\n",
        "# Filter ratings above 2\n",
        "merged_df = merged_df[merged_df['Book-Rating'] > 2]\n",
        "\n",
        "# Filter users aged less than 110\n",
        "merged_df = merged_df[merged_df['Age'] < 110]\n",
        "\n",
        "# Count the number of ratings by each user\n",
        "user_ratings_count = merged_df['User-ID'].value_counts()\n",
        "\n",
        "# Keep only users who have rated 3 or more books\n",
        "valid_users = user_ratings_count[user_ratings_count >= 2].index\n",
        "merged_df = merged_df[merged_df['User-ID'].isin(valid_users)]\n",
        "\n",
        "# Use only a fraction of the dataset\n",
        "merged_df = merged_df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Data Splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(merged_df, test_size=0.7, random_state=42)\n",
        "\n",
        "# Checking the transformations and missing values after preprocessing\n",
        "print(\"\\nData after preprocessing:\")\n",
        "print(\"Unique values in 'Year-Of-Publication':\", books_df['Year-Of-Publication'].unique())\n",
        "print(\"\\nMissing values after preprocessing:\")\n",
        "print(\"Users:\", users_df.isnull().sum())\n",
        "print(\"Books:\", books_df.isnull().sum())\n",
        "print(\"Ratings:\", ratings_df.isnull().sum())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Content Based Filtering**"
      ],
      "metadata": {
        "id": "kqtkaoO73hqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Weighted rating scores of each book for prediction\n",
        "\n",
        "### NOTE: May not need"
      ],
      "metadata": {
        "id": "cN0ElrkA3pZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# Function that computes the weighted rating of each book\n",
        "# We are utilizing the IMDB formula for weighted average ratings\n",
        "def weighted_rating(dataframe, m, C):\n",
        "    v = dataframe['Rating_Count']\n",
        "    R = dataframe['Average_Rating']\n",
        "    return (v / (v + m) * R) + (m / (m + v) * C)\n",
        "\n",
        "# Count the amount of ratings\n",
        "book_rated_count = ratings_df['ISBN'].value_counts().reset_index()\n",
        "book_rated_count.columns = ['ISBN', 'Rating_Count']\n",
        "\n",
        "# print(book_rated_count)\n",
        "\n",
        "# Calculate the average of the ratings for each book\n",
        "average_ratings = merged_df.groupby('ISBN')['Book-Rating'].mean().reset_index()\n",
        "average_ratings.columns = ['ISBN', 'Average_Rating']\n",
        "sorted_ratings = average_ratings.sort_values(by='Average_Rating', ascending=False)\n",
        "\n",
        "# Merge the book count and average ratings\n",
        "merged_data = pd.merge(book_rated_count, average_ratings, on='ISBN', how='inner')\n",
        "\n",
        "# Calculate mean of 'Average_Rating' column\n",
        "C = average_ratings['Average_Rating'].mean()\n",
        "print(\"Mean Average Rating:\", C)\n",
        "\n",
        "# Calculate the minimum number of ratings required to be in the chart, m\n",
        "m = book_rated_count['Rating_Count'].quantile(0.80)\n",
        "print(\"Minimum ratings required:\", m)\n",
        "\n",
        "# Filter out all qualified books into a new DataFrame\n",
        "q_books = merged_data.copy().loc[book_rated_count['Rating_Count'] >= m]\n",
        "\n",
        "# Apply weighted rating function to calculate the weighted rating for each book\n",
        "q_books['Weighted_Rating'] = q_books.apply(weighted_rating, axis=1, m=m, C=C)\n",
        "\n",
        "# Sorting the DataFrame by 'Weighted_Rating' in descending order\n",
        "sorted_q_books = q_books.sort_values(by='Weighted_Rating', ascending=False)\n",
        "\n",
        "# Print the result\n",
        "print(sorted_q_books)\n"
      ],
      "metadata": {
        "id": "jL2zDq8M7wob",
        "outputId": "3467cf9a-3789-43fd-a95e-4e7bd07a167c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Average Rating: 7.699436189271788\n",
            "Minimum ratings required: 3.0\n",
            "           ISBN  Rating_Count  Average_Rating  Weighted_Rating\n",
            "36   044022165X           386            10.0         9.982258\n",
            "40   0060502258           376            10.0         9.981790\n",
            "56   043935806X           334            10.0         9.979520\n",
            "59   0060938455           321            10.0         9.978698\n",
            "69   0061009059           291            10.0         9.976525\n",
            "..          ...           ...             ...              ...\n",
            "370  0425142485            90             3.0         3.151595\n",
            "308  0688177859           108             3.0         3.127012\n",
            "223  0451202341           145             3.0         3.095259\n",
            "222  0786885688           145             3.0         3.095259\n",
            "196  031242227X           161             3.0         3.085965\n",
            "\n",
            "[3163 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Content Based Recommendation using book title and author\n",
        "We will use content based filtering to create part of our recommendation system. We will use book information for this part. The book information includes: Book title and author"
      ],
      "metadata": {
        "id": "l6S2pChFMF5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Create content dataframe with only the book title and author\n",
        "content_df = merged_df[['Book-Title', 'Book-Author']].copy()\n",
        "\n",
        "# Combine the title and author and store in Book-Information column\n",
        "content_df['Book-Information'] = content_df['Book-Title'] + ' ' + content_df['Book-Author']\n",
        "\n",
        "# Drop all duplicate rows based on the 'Book-Information' column\n",
        "content_df = content_df.drop_duplicates(subset='Book-Information')\n",
        "\n",
        "# Reset the index after dropping duplicates\n",
        "content_df = content_df.reset_index(drop=True)\n",
        "\n",
        "# Construct the required TF-IDF matrix for all books information\n",
        "books_tfidf_matrix = tfidf.fit_transform(content_df['Book-Information'])\n",
        "\n",
        "# Calculate cosine similarity of the books matrix\n",
        "similarity = linear_kernel(books_tfidf_matrix, books_tfidf_matrix)\n",
        "\n",
        "def content_based_recommendations(book_title, book_author, similarity_matrix, df, top_n):\n",
        "    # Combine title and author for the given book\n",
        "    input_book_info = book_title + ' ' + book_author\n",
        "\n",
        "    # Get the index of the input book\n",
        "    input_book_index = df[df['Book-Information'] == input_book_info].index[0]\n",
        "\n",
        "    # Get the cosine similarity using the precomputed similarity matrix\n",
        "    similarity_scores = similarity_matrix[input_book_index]\n",
        "\n",
        "    # Get the indices of the top-n most similar books\n",
        "    top_indices = similarity_scores.argsort()[-top_n-1:-1]\n",
        "\n",
        "    # Return the top-n most similar books\n",
        "    return df.loc[top_indices, 'Book-Title']\n"
      ],
      "metadata": {
        "id": "8v30Macn4A2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_OF_RECOMMENDED_BOOKS = 5\n",
        "\n",
        "# Use the random_state in the sample method\n",
        "random_row = train_data.sample(n=1)\n",
        "\n",
        "# Use recommend system to get a content based recommendation of the top 5 books for the user\n",
        "book_title = random_row['Book-Title'].values[0]\n",
        "book_author = random_row['Book-Author'].values[0]\\\n",
        "\n",
        "recommendations_existing_user = content_based_recommendations(book_title, book_author, similarity, content_df, NUM_OF_RECOMMENDED_BOOKS)\n",
        "\n",
        "print(f\"Recommendations for '{book_title}' by {book_author} (Existing User):\")\n",
        "print(recommendations_existing_user)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-J0MJWDKrfA",
        "outputId": "4b680739-4323-4a0f-ad8b-84c90ab1bbc1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for 'When Love Awaits' by Johanna Lindsey (Existing User):\n",
            "11027                          Once a Princess\n",
            "13362           A Man to Call My Own : A Novel\n",
            "16991                        Surrender My Love\n",
            "18577    A Loving Scoundrel (Lindsey, Johanna)\n",
            "10783                          A Pirate's Love\n",
            "Name: Book-Title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OTHER (DELETE BEFORE SUBMIT)"
      ],
      "metadata": {
        "id": "z975ITU63ntV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Create a user-item matrix\n",
        "user_item_matrix = pd.pivot_table(content_df, values='Book-Rating', index='User-ID', columns='ISBN', fill_value=0)\n",
        "\n",
        "print(content_df)\n",
        "print(user_item_matrix)\n",
        "# Calculate user-user cosine similarity\n",
        "user_similarity = cosine_similarity(user_item_matrix)\n",
        "\n",
        "# Function to get top N recommendations for a user using collaborative filtering\n",
        "def collaborative_filtering_recommendations(user_id, user_item_matrix, user_similarity, N=5):\n",
        "    # Get the target user's ratings\n",
        "    target_user_ratings = user_item_matrix.loc[user_id].values.reshape(1, -1)\n",
        "\n",
        "    # Calculate similarity scores between the target user and all other users\n",
        "    sim_scores = cosine_similarity(target_user_ratings, user_item_matrix.values)\n",
        "\n",
        "\n",
        "    # Get the indices of users with highest similarity scores\n",
        "    similar_users = np.argsort(sim_scores[0])[::-1][1:N+1]\n",
        "\n",
        "    print(similar_users)\n",
        "    # Get books that the target user hasn't rated\n",
        "    unrated_books = user_item_matrix.columns[user_item_matrix.loc[user_id] == 0]\n",
        "    print(unrated_books)\n",
        "\n",
        "    # Convert unrated_books to a list\n",
        "    unrated_books = unrated_books.tolist()\n",
        "\n",
        "    print(\"user_item_matrix shape:\", user_item_matrix)\n",
        "\n",
        "    # Get the average rating of each unrated book from similar users\n",
        "    average_ratings = np.mean(user_item_matrix.loc[similar_users, unrated_books], axis=0)\n",
        "\n",
        "    # Get top N recommendations\n",
        "    top_n_books = unrated_books[np.argsort(average_ratings)[::-1][:N]]\n",
        "\n",
        "    return top_n_books\n",
        "\n",
        "# Example usage\n",
        "target_user_id = 14559  # Replace with the actual user ID\n",
        "top_recommendations = collaborative_filtering_recommendations(target_user_id, user_item_matrix, user_similarity, N=5)\n",
        "\n",
        "# Display the top N recommended books\n",
        "recommended_books_info = books_df[books_df['ISBN'].isin(top_recommendations)]\n",
        "print(\"Top N Recommended Books:\")\n",
        "print(recommended_books_info[['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication']])\n"
      ],
      "metadata": {
        "id": "PGuD5lcAuFwu",
        "outputId": "ef280847-b1d4-47d4-b14c-80da68fba253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ISBN     0007154607  0020209851  0020518609  0020795904  006000438X  \\\n",
            "User-ID                                                               \n",
            "2276              0           0           0           0           0   \n",
            "6242              0           0           0           0           0   \n",
            "8067              0           0           0           0           0   \n",
            "11676             0           0           0           0           0   \n",
            "12100             0           0           0           0           0   \n",
            "\n",
            "ISBN     0060006293  0060086386  0060089539  0060109955  0060159383  ...  \\\n",
            "User-ID                                                              ...   \n",
            "2276              0           0           0           0           0  ...   \n",
            "6242              0           0           0           0           0  ...   \n",
            "8067              0           0           0           0           0  ...   \n",
            "11676             0           0           0           0           9  ...   \n",
            "12100             0           0           0           0           0  ...   \n",
            "\n",
            "ISBN     189206524X  1903845882  2266078720  2266125354  2850250481  \\\n",
            "User-ID                                                               \n",
            "2276              0           0           0           0           0   \n",
            "6242              0           0           0           0           0   \n",
            "8067              0           0           0           0           0   \n",
            "11676             0           0           0           8           0   \n",
            "12100             0           0           0           0           0   \n",
            "\n",
            "ISBN     843501634X  8466300473  8475960715  8483102161  9502802861  \n",
            "User-ID                                                              \n",
            "2276              0           0           0           0           0  \n",
            "6242              0           0           0           0           0  \n",
            "8067              0           0           0           0           0  \n",
            "11676             0           8           8           7           0  \n",
            "12100             0           0           0           0           0  \n",
            "\n",
            "[5 rows x 804 columns]\n",
            "        User-ID        ISBN  Book-Rating  \\\n",
            "184873    78973  0671039725            8   \n",
            "4137      98391  1551667487            9   \n",
            "743528     6242  0684865726            5   \n",
            "318821   156150  0380715430            8   \n",
            "9889     115435  0156106809            9   \n",
            "...         ...         ...          ...   \n",
            "30478     11676  044100508X            8   \n",
            "422810   189334  0395080487           10   \n",
            "68805     13552  0515128554            7   \n",
            "44186    158295  0451192311            6   \n",
            "420119    52853  0060526203            6   \n",
            "\n",
            "                                               Book-Title       Book-Author  \\\n",
            "184873                                             Carrie      Stephen King   \n",
            "4137                                         Return To Me   Rosemary Rogers   \n",
            "743528           True At First Light : A Fictional Memoir  Ernest Hemingway   \n",
            "318821                                  The Mother Tongue       Bill Bryson   \n",
            "9889                               The Baron in the Trees     Italo Calvino   \n",
            "...                                                   ...               ...   \n",
            "30478               The Pearls of Lutra (Redwall, Book 9)     Brian Jacques   \n",
            "422810  The natural way to draw: A working plan for ar...  Kimon Nicolaides   \n",
            "68805                    Heart of the Sea (Irish Trilogy)      Nora Roberts   \n",
            "44186   Eat Drink and Be Wary: A Pennsylvania Dutch My...       Tamar Myers   \n",
            "420119                                      Kiss Me Quick    Margaret Moore   \n",
            "\n",
            "        Year-Of-Publication            Publisher  \\\n",
            "184873               2002.0               Pocket   \n",
            "4137                 2003.0                 Mira   \n",
            "743528               2000.0             Scribner   \n",
            "318821               1991.0            Perennial   \n",
            "9889                 1977.0             Harcourt   \n",
            "...                     ...                  ...   \n",
            "30478                1998.0            Ace Books   \n",
            "422810               1975.0  Houghton Mifflin Co   \n",
            "68805                2000.0           Jove Books   \n",
            "44186                1998.0          Signet Book   \n",
            "420119               2003.0                 Avon   \n",
            "\n",
            "                                              Image-URL-S  \\\n",
            "184873  http://images.amazon.com/images/P/0671039725.0...   \n",
            "4137    http://images.amazon.com/images/P/1551667487.0...   \n",
            "743528  http://images.amazon.com/images/P/0684865726.0...   \n",
            "318821  http://images.amazon.com/images/P/0380715430.0...   \n",
            "9889    http://images.amazon.com/images/P/0156106809.0...   \n",
            "...                                                   ...   \n",
            "30478   http://images.amazon.com/images/P/044100508X.0...   \n",
            "422810  http://images.amazon.com/images/P/0395080487.0...   \n",
            "68805   http://images.amazon.com/images/P/0515128554.0...   \n",
            "44186   http://images.amazon.com/images/P/0451192311.0...   \n",
            "420119  http://images.amazon.com/images/P/0060526203.0...   \n",
            "\n",
            "                                              Image-URL-M  \\\n",
            "184873  http://images.amazon.com/images/P/0671039725.0...   \n",
            "4137    http://images.amazon.com/images/P/1551667487.0...   \n",
            "743528  http://images.amazon.com/images/P/0684865726.0...   \n",
            "318821  http://images.amazon.com/images/P/0380715430.0...   \n",
            "9889    http://images.amazon.com/images/P/0156106809.0...   \n",
            "...                                                   ...   \n",
            "30478   http://images.amazon.com/images/P/044100508X.0...   \n",
            "422810  http://images.amazon.com/images/P/0395080487.0...   \n",
            "68805   http://images.amazon.com/images/P/0515128554.0...   \n",
            "44186   http://images.amazon.com/images/P/0451192311.0...   \n",
            "420119  http://images.amazon.com/images/P/0060526203.0...   \n",
            "\n",
            "                                              Image-URL-L  \\\n",
            "184873  http://images.amazon.com/images/P/0671039725.0...   \n",
            "4137    http://images.amazon.com/images/P/1551667487.0...   \n",
            "743528  http://images.amazon.com/images/P/0684865726.0...   \n",
            "318821  http://images.amazon.com/images/P/0380715430.0...   \n",
            "9889    http://images.amazon.com/images/P/0156106809.0...   \n",
            "...                                                   ...   \n",
            "30478   http://images.amazon.com/images/P/044100508X.0...   \n",
            "422810  http://images.amazon.com/images/P/0395080487.0...   \n",
            "68805   http://images.amazon.com/images/P/0515128554.0...   \n",
            "44186   http://images.amazon.com/images/P/0451192311.0...   \n",
            "420119  http://images.amazon.com/images/P/0060526203.0...   \n",
            "\n",
            "                          Location   Age  \n",
            "184873   amadora, lisboa, portugal  29.0  \n",
            "4137          morrow, georgia, usa  52.0  \n",
            "743528    calgary, alberta, canada  32.0  \n",
            "318821     howell, new jersey, usa  36.0  \n",
            "9889         cincinnati, ohio, usa  30.0  \n",
            "...                            ...   ...  \n",
            "30478                n/a, n/a, n/a  32.0  \n",
            "422810     ottawa, ontario, canada  49.0  \n",
            "68805      cordova, tennessee, usa  32.0  \n",
            "44186         cleveland, ohio, usa  32.0  \n",
            "420119  yuba city, california, usa  61.0  \n",
            "\n",
            "[812 rows x 12 columns]\n",
            "ISBN     0007154607  0020209851  0020518609  0020795904  006000438X  \\\n",
            "User-ID                                                               \n",
            "2276              0           0           0           0           0   \n",
            "6242              0           0           0           0           0   \n",
            "8067              0           0           0           0           0   \n",
            "11676             0           0           0           0           0   \n",
            "12100             0           0           0           0           0   \n",
            "...             ...         ...         ...         ...         ...   \n",
            "264031            0           0           0           0           0   \n",
            "265313            0           0           0           0           0   \n",
            "269890            0           0           0           0           0   \n",
            "270713            0           0           0           0           0   \n",
            "271195            0           0           0           0           0   \n",
            "\n",
            "ISBN     0060006293  0060086386  0060089539  0060109955  0060159383  ...  \\\n",
            "User-ID                                                              ...   \n",
            "2276              0           0           0           0           0  ...   \n",
            "6242              0           0           0           0           0  ...   \n",
            "8067              0           0           0           0           0  ...   \n",
            "11676             0           0           0           0           9  ...   \n",
            "12100             0           0           0           0           0  ...   \n",
            "...             ...         ...         ...         ...         ...  ...   \n",
            "264031            0           0           0           0           0  ...   \n",
            "265313            0           0           0           0           0  ...   \n",
            "269890            0           0           0           0           0  ...   \n",
            "270713            0           0           0           0           0  ...   \n",
            "271195            0           0           0           0           0  ...   \n",
            "\n",
            "ISBN     189206524X  1903845882  2266078720  2266125354  2850250481  \\\n",
            "User-ID                                                               \n",
            "2276              0           0           0           0           0   \n",
            "6242              0           0           0           0           0   \n",
            "8067              0           0           0           0           0   \n",
            "11676             0           0           0           8           0   \n",
            "12100             0           0           0           0           0   \n",
            "...             ...         ...         ...         ...         ...   \n",
            "264031            0           0           0           0           0   \n",
            "265313            0           0           0           0           7   \n",
            "269890            0           0           0           0           0   \n",
            "270713            0           0           0           0           0   \n",
            "271195            0           0           0           0           0   \n",
            "\n",
            "ISBN     843501634X  8466300473  8475960715  8483102161  9502802861  \n",
            "User-ID                                                              \n",
            "2276              0           0           0           0           0  \n",
            "6242              0           0           0           0           0  \n",
            "8067              0           0           0           0           0  \n",
            "11676             0           8           8           7           0  \n",
            "12100             0           0           0           0           0  \n",
            "...             ...         ...         ...         ...         ...  \n",
            "264031            0           0           0           0           0  \n",
            "265313            0           0           0           0           0  \n",
            "269890            0           0           0           0           0  \n",
            "270713            0           0           0           0           0  \n",
            "271195            0           0           0           0           0  \n",
            "\n",
            "[158 rows x 804 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 14559",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-39a1fd1c3bce>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mtarget_user_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m14559\u001b[0m  \u001b[0;31m# Replace with the actual user ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mtop_recommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollaborative_filtering_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_user_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_item_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Display the top N recommended books\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-39a1fd1c3bce>\u001b[0m in \u001b[0;36mcollaborative_filtering_recommendations\u001b[0;34m(user_id, user_item_matrix, user_similarity, N)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcollaborative_filtering_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_item_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Get the target user's ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtarget_user_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_item_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Calculate similarity scores between the target user and all other users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1310\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;31m# GH#5567 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4054\u001b[0m                     \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4055\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4056\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4058\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 14559"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55pvZjwMOQDF",
        "outputId": "caff33be-0263-4efe-a29b-e55150f27a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-9d4083447471>\u001b[0m in \u001b[0;36m<cell line: 146>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0mtop_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# Number of recommendations to return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m \u001b[0mrecommended_books\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent_based_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooks_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Based Recommendations:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommended_books\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-9d4083447471>\u001b[0m in \u001b[0;36mcontent_based_recommendations\u001b[0;34m(books_df, ratings_df, user_id, threshold, top_n)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Get the similarity between all books and the books that user recommended\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mcontent_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_tfidf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbooks_tfidf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_similarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1391\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    178\u001b[0m             )\n\u001b[1;32m    179\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;34m\"Incompatible dimension for X and Y matrices: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;34m\"X.shape[1] == %d while Y.shape[1] == %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 26 while Y.shape[1] == 387830"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Collaborative Filtering based on users' age\n",
        "# def collaborative_filtering(user_age, train_data, users_df):\n",
        "#     # Filter users based on age\n",
        "#     filtered_users = users_df[users_df['Age'] == user_age]\n",
        "\n",
        "#     # Filter training data based on selected users and non-zero ratings\n",
        "#     filtered_train_data = train_data[(train_data['User-ID'].isin(filtered_users['User-ID'])) & (train_data['Book-Rating'] != 0)]\n",
        "\n",
        "#     # Create a user-item matrix for collaborative filtering\n",
        "#     user_item_matrix = filtered_train_data.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating')\n",
        "#     user_item_matrix = user_item_matrix.fillna(0)\n",
        "\n",
        "#     print(user_item_matrix)\n",
        "#     # Calculate cosine similarity between users\n",
        "#     cosine_sim_users = cosine_similarity(user_item_matrix, user_item_matrix)\n",
        "\n",
        "#     return cosine_sim_users\n",
        "\n",
        "# Content-Based Filtering based on book ratings\n",
        "# def content_based_filtering(train_data, books_df):\n",
        "#     # Get the top N books with the highest average ratings\n",
        "#     # top_books = train_data.groupby('ISBN')['Book-Rating'].mean().reset_index()\n",
        "#     # top_books = top_books.sort_values(by='Book-Rating', ascending=False)\n",
        "\n",
        "#     # print(top_books)\n",
        "#     # # Merge with books_df to get additional book information\n",
        "#     # top_books = pd.merge(top_books, books_df, on='ISBN')\n",
        "\n",
        "#     # Create a TF-IDF vectorizer for book titles\n",
        "#     tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "#     tfidf_matrix = tfidf_vectorizer.fit_transform(train_data['Book-Rating'])\n",
        "\n",
        "#     print(tfidf_matrix)\n",
        "\n",
        "#     # # Apply Truncated SVD for dimensionality reduction\n",
        "#     # svd = TruncatedSVD(n_components=100)\n",
        "#     # tfidf_matrix_reduced = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "#     # # Calculate the cosine similarity between book titles\n",
        "#     # cosine_sim_books = cosine_similarity(tfidf_matrix_reduced, tfidf_matrix_reduced)\n",
        "#     # print(cosine_sim_books)\n",
        "#     # return cosine_sim_books\n",
        "\n",
        "\n",
        "# def jaccard_similarity(content_matrix):\n",
        "#     # Convert the sparse matrix to a dense matrix\n",
        "#     dense_content_matrix = content_matrix.toarray()\n",
        "\n",
        "#     # Compute Jaccard similarity using pairwise_distances with metric='jaccard'\n",
        "#     jaccard_sim = 1 - pairwise_distances(dense_content_matrix, metric='jaccard')\n",
        "#     return normalize(jaccard_sim, axis=1, norm='l1')  # Normalize the similarity scores\n",
        "\n",
        "# def content_based_filtering(content_df):\n",
        "#     # Sort by ratings and select the top 10,000 rows\n",
        "#     print(content_df)\n",
        "#     books_df = content_df[['Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Book-Rating']]\n",
        "\n",
        "#     # Puts all features in a string\n",
        "#     books_df['Content'] = books_df.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
        "\n",
        "#     print('--------')\n",
        "#     print(books_df)\n",
        "\n",
        "#     tfidf_vectorizer = TfidfVectorizer()\n",
        "#     content_matrix = tfidf_vectorizer.fit_transform(books_df['Content'])\n",
        "\n",
        "#     content_similarity = cosine_similarity(content_matrix, content_matrix)\n",
        "\n",
        "#     return books_df, content_similarity, tfidf_vectorizer\n",
        "\n",
        "# # Example usage\n",
        "# books_df = pd.read_csv('Books.csv')  # Load books data\n",
        "# content_df, content_similarity, tfidf_vectorizer = content_based_filtering(books_df, top_n=10000)\n",
        "\n",
        "\n",
        "# # Hybrid Recommender System\n",
        "# def hybrid_recommender(user_age, user_id, train_data, books_df, users_df):\n",
        "#     # Collaborative Filtering\n",
        "#     # collaborative_results = collaborative_filtering(user_age, train_data, users_df)\n",
        "\n",
        "#     # Content-Based Filtering\n",
        "#     content_based_results = content_based_filtering(train_data)\n",
        "#     # # Combine the results using a weighted sum\n",
        "#     # # Note: Here, we use the mean rating from collaborative filtering\n",
        "#     # # and the cosine similarity values from content-based filtering\n",
        "#     # collaborative_results_df = pd.DataFrame(collaborative_results)\n",
        "#     # collaborative_results_df = collaborative_results_df.fillna(0)\n",
        "\n",
        "#     # hybrid_results = pd.DataFrame(index=train_data['User-ID'], columns=train_data['ISBN'])\n",
        "#     # hybrid_results['Hybrid-Score'] = (0.5 * collaborative_results_df.values +\n",
        "#     #                                    0.5 * content_based_results.loc[collaborative_results_df.index, collaborative_results_df.columns].fillna(0))\n",
        "\n",
        "#     # # Sort the results by Hybrid-Score in descending order\n",
        "#     # recommended_books = hybrid_results.unstack().reset_index(name='Hybrid-Score')\n",
        "#     # user_rated_books = train_data[train_data['User-ID'] == user_id]['ISBN']\n",
        "#     # recommended_books = recommended_books[~recommended_books['ISBN'].isin(user_rated_books)]\n",
        "\n",
        "#     # return recommended_books[['ISBN', 'Hybrid-Score']].nlargest(5, 'Hybrid-Score')\n",
        "#     return\n",
        "\n",
        "def content_based_recommendations(books_df, ratings_df, user_id, threshold=5, top_n=10):\n",
        "    # Filter ratings data for the user and ratings above the threshold\n",
        "    user_ratings = ratings_df[(ratings_df['User-ID'] == user_id)]\n",
        "\n",
        "    # Get the ISBNs of positively rated books by the user\n",
        "    positively_rated_isbns = user_ratings['ISBN'].unique()\n",
        "\n",
        "    # Filter content data for positively rated books\n",
        "    positively_rated_books_df = books_df[books_df['ISBN'].isin(positively_rated_isbns)].drop('ISBN', axis=1)\n",
        "\n",
        "    # Drop ISBN from books as we will not use that to compare\n",
        "    all_books = books_df.drop('ISBN', axis=1)\n",
        "\n",
        "    # Create the 'Content' column without including the 'ISBN'; this will create a string of all the info about that book\n",
        "    positively_rated_books_df['Content'] = positively_rated_books_df.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
        "    all_books['Content'] = all_books.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
        "\n",
        "    # Apply content-based filtering to recommend similar books\n",
        "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    content_tfidf_matrix = tfidf_vectorizer.fit_transform(positively_rated_books_df['Content'])\n",
        "    books_tfidf_matrix = tfidf_vectorizer.fit_transform(all_books['Content'])\n",
        "\n",
        "    # Get the similarity between all books and the books that user recommended\n",
        "    content_similarity = cosine_similarity(content_tfidf_matrix, books_tfidf_matrix)\n",
        "\n",
        "    print(content_similarity)\n",
        "\n",
        "    # Identify books similar to the positively rated ones\n",
        "    similar_books_indices = content_similarity.argsort(axis=1)[:, ::-1][:, :top_n]\n",
        "    similar_books_info = positively_rated_books_df.iloc[similar_books_indices.flatten()]\n",
        "\n",
        "    return similar_books_info\n",
        "\n",
        "# Example usage\n",
        "user_id = 276729  # Replace with the actual user ID\n",
        "threshold = 5  # Ratings above this threshold will be considered\n",
        "top_n = 10  # Number of recommendations to return\n",
        "\n",
        "recommended_books = content_based_recommendations(books_df, ratings_df, user_id, threshold, top_n)\n",
        "print(\"Content-Based Recommendations:\", recommended_books)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qg1t5VTTUA7Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cN0ElrkA3pZI",
        "z975ITU63ntV"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}