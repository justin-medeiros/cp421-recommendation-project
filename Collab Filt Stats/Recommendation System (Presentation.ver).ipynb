{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "va5H-Oe6OPF7"
   },
   "source": [
    "# CP421 Final Project\n",
    "\n",
    "Book Recommendation System\n",
    "\n",
    "- Justin Medeiros (200744390) [Team Lead]\n",
    "- Peranvan Paralogasingam (190867830)\n",
    "- Jack Pham (200530610)\n",
    "- Levi Van Veen (200852490)\n",
    "- Ratul Sarker (203087260)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ff4UOlhiOPF-",
    "outputId": "a6aa3809-8ed6-496b-fae6-e84b43a9ea40"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silve\\AppData\\Local\\Temp\\ipykernel_22768\\348323183.py:10: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books_df = pd.read_csv(books_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after preprocessing:\n",
      "Unique values in 'Year-Of-Publication': [2002. 2001. 1991. 1999. 2000. 1993. 1996. 1988. 2004. 1998. 1994. 2003.\n",
      " 1997. 1983. 1979. 1995. 1982. 1985. 1992. 1986. 1978. 1980. 1952. 1987.\n",
      " 1990. 1981. 1989. 1984.    0. 1968. 1961. 1958. 1974. 1976. 1971. 1977.\n",
      " 1975. 1965. 1941. 1970. 1962. 1973. 1972. 1960. 1966. 1920. 1956. 1959.\n",
      " 1953. 1951. 1942. 1963. 1964. 1969. 1954. 1950. 1967. 2005. 1957. 1940.\n",
      " 1937. 1955. 1946. 1936. 1930. 2011. 1925. 1948. 1943. 1947. 1945. 1923.\n",
      " 2020. 1939. 1926. 1938. 2030. 1911. 1904. 1949. 1932. 1928. 1929. 1927.\n",
      " 1931. 1914. 2050. 1934. 1910. 1933. 1902. 1924. 1921. 1900. 2038. 2026.\n",
      " 1944. 1917. 1901. 2010. 1908. 1906. 1935. 1806. 2021. 2012. 2006. 1909.\n",
      " 2008. 1378. 1919. 1922. 1897. 2024. 1376. 2037.]\n",
      "\n",
      "Missing values after preprocessing:\n",
      "Users: User-ID     0\n",
      "Location    0\n",
      "Age         0\n",
      "dtype: int64\n",
      "Books: ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            0\n",
      "Year-Of-Publication    0\n",
      "Publisher              0\n",
      "dtype: int64\n",
      "Ratings: User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#DATA PRECPROCESSING-----------------------------------------------------------------------------------------------\n",
    "\n",
    "# File paths\n",
    "users_file = 'Users.csv'\n",
    "books_file = 'Books.csv'\n",
    "ratings_file = 'Ratings.csv'\n",
    "\n",
    "# Load the datasets\n",
    "users_df = pd.read_csv(users_file)\n",
    "books_df = pd.read_csv(books_file)\n",
    "ratings_df = pd.read_csv(ratings_file)\n",
    "\n",
    "# Users Data Preprocessing\n",
    "# Handle missing values in 'Age' and 'Location'\n",
    "users_df['Age'].fillna(users_df['Age'].median(), inplace=True)\n",
    "users_df['Location'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# Books Data Preprocessing\n",
    "# Convert 'Year-Of-Publication' to numeric and handle non-numeric values\n",
    "books_df['Year-Of-Publication'] = pd.to_numeric(books_df['Year-Of-Publication'], errors='coerce')\n",
    "books_df['Year-Of-Publication'].fillna(books_df['Year-Of-Publication'].median(), inplace=True)\n",
    "# Handle missing values in 'Book-Author' and 'Publisher'\n",
    "books_df['Book-Author'].fillna('Unknown', inplace=True)\n",
    "books_df['Publisher'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Drop the url columns as we will not be using them\n",
    "books_df.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis=1, inplace=True)\n",
    "\n",
    "# Ratings Data Preprocessing\n",
    "# Merge 'Ratings' with 'Books' to filter out books not in the 'Books' dataset\n",
    "ratings_df = ratings_df[ratings_df['ISBN'].isin(books_df['ISBN'])]\n",
    "\n",
    "# Merge books_df, users_df, and ratings_df\n",
    "merged_df = pd.merge(ratings_df, books_df, on='ISBN', how='inner')\n",
    "merged_df = pd.merge(merged_df, users_df, on='User-ID', how='inner')\n",
    "\n",
    "# Filter ratings above 0\n",
    "merged_df = merged_df[merged_df['Book-Rating'] > 0]\n",
    "\n",
    "# Filter users aged less than 110\n",
    "merged_df = merged_df[merged_df['Age'] < 110]\n",
    "\n",
    "# Count the number of ratings by each user\n",
    "user_ratings_count = merged_df['User-ID'].value_counts()\n",
    "\n",
    "# Keep only users who have rated 3 or more books\n",
    "valid_users = user_ratings_count[user_ratings_count >= 2].index\n",
    "merged_df = merged_df[merged_df['User-ID'].isin(valid_users)]\n",
    "\n",
    "# Use only a fraction of the dataset\n",
    "merged_df = merged_df.sample(frac=0.01, random_state=42)\n",
    "\n",
    "# Data Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(merged_df, test_size=0.7, random_state=42)\n",
    "\n",
    "# Checking the transformations and missing values after preprocessing\n",
    "print(\"\\nData after preprocessing:\")\n",
    "print(\"Unique values in 'Year-Of-Publication':\", books_df['Year-Of-Publication'].unique())\n",
    "print(\"\\nMissing values after preprocessing:\")\n",
    "print(\"Users:\", users_df.isnull().sum())\n",
    "print(\"Books:\", books_df.isnull().sum())\n",
    "print(\"Ratings:\", ratings_df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqtkaoO73hqn"
   },
   "source": [
    "# **Content Based Filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cN0ElrkA3pZI"
   },
   "source": [
    "### 1. Weighted rating scores of each book for prediction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jL2zDq8M7wob",
    "outputId": "35745a20-fc83-40bf-c50e-117c584655ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Rating: 7.665682370662014\n",
      "Minimum ratings required: 3.0\n",
      "           ISBN  Rating_Count  Average_Rating  Weighted_Rating\n",
      "35   0385484518           391            10.0         9.982226\n",
      "36   0446310786           389            10.0         9.982135\n",
      "47   0440206154           365            10.0         9.980970\n",
      "87   1558743669           262            10.0         9.973574\n",
      "91   0345339703           257            10.0         9.973066\n",
      "..          ...           ...             ...              ...\n",
      "461  044011585X            76             2.0         2.215152\n",
      "390  0060188731            91             2.0         2.180820\n",
      "825  3442433495            36             1.0         1.512745\n",
      "317  0679735771           110             1.0         1.176965\n",
      "108  0064407667           230             1.0         1.085824\n",
      "\n",
      "[3193 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Function that computes the weighted rating of each book\n",
    "# We are utilizing the IMDB formula for weighted average ratings\n",
    "def weighted_rating(dataframe, m, C):\n",
    "    v = dataframe['Rating_Count']\n",
    "    R = dataframe['Average_Rating']\n",
    "    return (v / (v + m) * R) + (m / (m + v) * C)\n",
    "\n",
    "# Count the amount of ratings\n",
    "book_rated_count = ratings_df['ISBN'].value_counts().reset_index()\n",
    "book_rated_count.columns = ['ISBN', 'Rating_Count']\n",
    "\n",
    "# print(book_rated_count)\n",
    "global_mean = merged_df['Book-Rating'].mean()\n",
    "\n",
    "# Calculate the average of the ratings for each book\n",
    "average_ratings = merged_df.groupby('ISBN')['Book-Rating'].mean().reset_index()\n",
    "\n",
    "# Merge the book_means DataFrame with the original DataFrame to fill missing ratings in user-book matrix\n",
    "merged_df = pd.merge(merged_df, average_ratings, on='ISBN', how='left', suffixes=('_original', '_mean'))\n",
    "merged_df['Book-Rating'] = merged_df['Book-Rating_original'].combine_first(merged_df['Book-Rating_mean'])\n",
    "merged_df.drop(['Book-Rating_original', 'Book-Rating_mean'], axis=1, inplace=True)\n",
    "\n",
    "average_ratings.columns = ['ISBN', 'Average_Rating']\n",
    "sorted_ratings = average_ratings.sort_values(by='Average_Rating', ascending=False)\n",
    "\n",
    "# Merge the book count and average ratings\n",
    "merged_data = pd.merge(book_rated_count, average_ratings, on='ISBN', how='inner')\n",
    "\n",
    "# Calculate mean of 'Average_Rating' column\n",
    "C = average_ratings['Average_Rating'].mean()\n",
    "print(\"Mean Average Rating:\", C)\n",
    "\n",
    "# Calculate the minimum number of ratings required to be in the chart, m\n",
    "m = book_rated_count['Rating_Count'].quantile(0.80)\n",
    "print(\"Minimum ratings required:\", m)\n",
    "\n",
    "# Filter out all qualified books into a new DataFrame\n",
    "q_books = merged_data.copy().loc[book_rated_count['Rating_Count'] >= m]\n",
    "\n",
    "# Apply weighted rating function to calculate the weighted rating for each book\n",
    "q_books['Weighted_Rating'] = q_books.apply(weighted_rating, axis=1, m=m, C=C)\n",
    "\n",
    "# Sorting the DataFrame by 'Weighted_Rating' in descending order\n",
    "sorted_q_books = q_books.sort_values(by='Weighted_Rating', ascending=False)\n",
    "\n",
    "# Print the result\n",
    "print(sorted_q_books)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improves accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6S2pChFMF5n"
   },
   "source": [
    "### 2. Content Based Recommendation using book title and author\n",
    "We will use content based filtering to create part of our recommendation system. We will use book information for this part. The book information includes: Book title and author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8v30Macn4A2k"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Create content dataframe with only the book title and author\n",
    "content_df = merged_df[['Book-Title', 'Book-Author', 'ISBN']].copy()\n",
    "\n",
    "# Combine the title and author and store in Book-Information column\n",
    "content_df['Book-Information'] = content_df['Book-Title'] + ' ' + content_df['Book-Author']\n",
    "\n",
    "# Drop all duplicate rows based on the 'Book-Information' column\n",
    "content_df = content_df.drop_duplicates(subset='Book-Information')\n",
    "\n",
    "# Reset the index after dropping duplicates\n",
    "content_df = content_df.reset_index(drop=True)\n",
    "\n",
    "# Construct the required TF-IDF matrix for all books information\n",
    "books_tfidf_matrix = tfidf.fit_transform(content_df['Book-Information'])\n",
    "\n",
    "# Calculate cosine similarity of the books matrix\n",
    "similarity = linear_kernel(books_tfidf_matrix, books_tfidf_matrix)\n",
    "\n",
    "def content_based_recommendations(book_title, book_author, top_n, similarity_matrix=similarity, df=content_df):\n",
    "    # Combine title and author for the given book\n",
    "    input_book_info = book_title + ' ' + book_author\n",
    "\n",
    "    # Get the index of the input book\n",
    "    input_book_index = df[df['Book-Information'] == input_book_info].index[0]\n",
    "\n",
    "    # Get the cosine similarity using the precomputed similarity matrix\n",
    "    similarity_scores = similarity_matrix[input_book_index]\n",
    "\n",
    "    # Get the indices of the top-n most similar books\n",
    "    top_indices = similarity_scores.argsort()[-top_n-1:-1]\n",
    "\n",
    "    # Return the top-n most similar books\n",
    "    return df.loc[top_indices, ['ISBN', 'Book-Title', 'Book-Author']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r-J0MJWDKrfA",
    "outputId": "d075aeed-fe43-4e98-c77f-d4526a7ee2d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'Left Behind: A Novel of the Earth's Last Days (Left Behind #1)' by Tim Lahaye (Existing User):\n",
      "            ISBN                                         Book-Title  \\\n",
      "2396  0500542384                    The Earth from the Air 365 Days   \n",
      "532   0842329269  Apollyon: The Destroyer Is Unleashed (Left Beh...   \n",
      "2272  0842332340  Armageddon: The Cosmic Battle of the Ages (Lef...   \n",
      "1381  0842332286  The Mark: The Beast Rules the World (Left Behi...   \n",
      "51    0842329129  Left Behind: A Novel of the Earth's Last Days ...   \n",
      "\n",
      "               Book-Author  \n",
      "2396  Yann Arthus-bertrand  \n",
      "532          Jerry Jenkins  \n",
      "2272         Tim F. LaHaye  \n",
      "1381            Tim Lahaye  \n",
      "51              Tim Lahaye  \n"
     ]
    }
   ],
   "source": [
    "NUM_OF_RECOMMENDED_BOOKS = 5\n",
    "\n",
    "# Use the random_state in the sample method\n",
    "random_row = train_data.sample(n=1)\n",
    "\n",
    "# Use recommend system to get a content based recommendation of the top 5 books for the user\n",
    "book_title = random_row['Book-Title'].values[0]\n",
    "book_author = random_row['Book-Author'].values[0]\n",
    "\n",
    "recommendations_existing_user = content_based_recommendations(book_title, book_author, NUM_OF_RECOMMENDED_BOOKS)\n",
    "\n",
    "print(f\"Recommendations for '{book_title}' by {book_author} (Existing User):\")\n",
    "print(recommendations_existing_user)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds books with close consine similarity based on title/author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1Q6QJYezM4q"
   },
   "source": [
    "# **Collaborative Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "gnUcLmcuzM4q",
    "outputId": "11f1dbe8-f990-480b-b6d3-0effd8beea19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISBN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>044021145X</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400034779</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0553279912</th>\n",
       "      <td>8.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0802135226</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0060928336</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0553801929</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>067976402X</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0380769557</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0679745203</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0684874350</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Book-Rating  num_ratings\n",
       "ISBN                                \n",
       "044021145X     9.000000            3\n",
       "1400034779     7.000000            3\n",
       "0553279912     8.333333            3\n",
       "0802135226     8.500000            2\n",
       "0060928336     7.000000            2\n",
       "0553801929     7.500000            2\n",
       "067976402X     8.500000            2\n",
       "0380769557     7.500000            2\n",
       "0679745203     9.000000            2\n",
       "0684874350     7.000000            2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.DataFrame(train_data.groupby('ISBN')['Book-Rating'].mean())\n",
    "\n",
    "ratings['num_ratings'] = pd.DataFrame(train_data.groupby('ISBN')['Book-Rating'].count())\n",
    "ratings.head()\n",
    "\n",
    "bookmat = train_data.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating')\n",
    "bookmat.head()\n",
    "\n",
    "ratings.sort_values('num_ratings', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "IQWJ0mqvzM4r",
    "outputId": "d5d2785f-f1ee-4951-a14f-9d29c6d7db73",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'algorithm': 'auto', 'metric': 'euclidean', 'n_neighbors': 40}\n",
      "Best RMSE:  1.851416997740723\n",
      "Test RMSE:  1.7830938716698912\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "isbn_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the ISBN column\n",
    "merged_df['ISBN_encoded'] = isbn_encoder.fit_transform(merged_df['ISBN'])\n",
    "test_data['ISBN_encoded'] = isbn_encoder.transform(test_data['ISBN'])\n",
    "\n",
    "# Convert the ISBN column to a numpy array\n",
    "x_train_global_mean = merged_df[['User-ID', 'ISBN_encoded', 'Book-Rating']].to_numpy()\n",
    "x_test = test_data[['User-ID', 'ISBN_encoded']].to_numpy()\n",
    "\n",
    "# Specify parameter grid for KNN\n",
    "param_grid = {\n",
    "    'n_neighbors': [40, 45, 50],\n",
    "    'algorithm': ['auto'],\n",
    "    'metric': ['euclidean', 'manhattan', 'chebyshev'],\n",
    "}\n",
    "\n",
    "# Create KNN model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "gs = GridSearchCV(knn_model, param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "try:\n",
    "    gs.fit(x_train_global_mean[:, :-1], x_train_global_mean[:, -1])\n",
    "except ValueError as e:\n",
    "    print(f\"Error during grid search. Error: {e}\")\n",
    "\n",
    "# Print the best parameters and corresponding RMSE\n",
    "print(\"Best Parameters: \", gs.best_params_)\n",
    "print(\"Best RMSE: \", (-gs.best_score_) ** 0.5)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = gs.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "test_rmse = mean_squared_error(test_data['Book-Rating'], test_predictions) ** 0.5\n",
    "print(\"Test RMSE: \", test_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root-mean-square-error(RMSE) showing average deviation of prediction versus the actual rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0MoaniizM4r",
    "outputId": "e622d683-39ae-4153-f83c-d7d072063e61"
   },
   "outputs": [],
   "source": [
    "def collaborative_recommendations(user_id, book_isbn, isbn_encoder=isbn_encoder, model=gs):\n",
    "    try:\n",
    "        # Encode the ISBN for the given book\n",
    "        book_encoded = isbn_encoder.transform([book_isbn])[0]\n",
    "\n",
    "        # Predict the rating for the given user and book\n",
    "        prediction = model.predict([[user_id, book_encoded]])[0]\n",
    "        return prediction\n",
    "    except ValueError:\n",
    "        print(\"User ID or ISBN not found in dataset.\")\n",
    "        return global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "STAC9sdKzM4s",
    "outputId": "830079ef-2966-4be9-f862-d948399f98b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user 100906 and book 0446672289: 7.65\n",
      "Actual rating for user 100906 and book 0446672289: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Get a random user from the test set\n",
    "    user_id = test_data.sample(n=1)['User-ID'].values[0]\n",
    "    # get a random book from the test set that the user has rated\n",
    "    book_isbn = test_data[test_data['User-ID'] == user_id].sample(n=1)['ISBN'].values[0]\n",
    "\n",
    "    predicted_rating = collaborative_recommendations(user_id, book_isbn)\n",
    "    \n",
    "    print(f\"Predicted rating for user {user_id} and book {book_isbn}: {predicted_rating}\")\n",
    "    # Print actual rating for the book\n",
    "    print(f\"Actual rating for user {user_id} and book {book_isbn}: {test_data[(test_data['User-ID'] == user_id) & (test_data['ISBN'] == book_isbn)]['Book-Rating'].values[0]}\")\n",
    "    print()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative Recommender predicts rating for specific book & user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H7_-5dG7LfW"
   },
   "source": [
    "### **Hybrid Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "d8dvEUXu7K-4",
    "outputId": "d0b6796c-4abe-4fc3-a25d-30e80c5d7556",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Selected Row:\n",
      "      User-ID                                         Book-Title  \\\n",
      "2909    31468  Permed to Death (Bad Hair Day Mysteries (Paper...   \n",
      "\n",
      "         Book-Author  \n",
      "2909  Nancy J. Cohen  \n",
      "------------------------\n",
      "                                           Book-Title             Book-Author  \\\n",
      "17  Other People's Skeletons (Rebecca Schwartz Mys...             Julie Smith   \n",
      "3                  1984 (Signet Classics (Paperback))           George Orwell   \n",
      "57                         The World's Last Mysteries         Reader's Digest   \n",
      "74                                 Word for Every Day        Alvin N. Rogness   \n",
      "55                                   Jewels of Elvish  Nancy Varian Berberick   \n",
      "..                                                ...                     ...   \n",
      "41   Have a Nice Day : A Tale of Blood and Sweatsocks              Mick Foley   \n",
      "67  The Bad Beginning (A Series of Unfortunate Eve...          Lemony Snicket   \n",
      "51                       The Death of Vishnu: A Novel              Manil Suri   \n",
      "2             Pyramids (Discworld Novels (Paperback))         Terry Pratchett   \n",
      "86                        Stand By Your Man : A Novel       Nancy Bartholomew   \n",
      "\n",
      "    Predicted-Rating  \n",
      "17             7.275  \n",
      "3              7.275  \n",
      "57             7.275  \n",
      "74             7.275  \n",
      "55             7.275  \n",
      "..               ...  \n",
      "41             6.875  \n",
      "67             6.875  \n",
      "51             6.875  \n",
      "2              6.875  \n",
      "86             6.875  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Predicted-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Other People's Skeletons (Rebecca Schwartz Mys...</td>\n",
       "      <td>Julie Smith</td>\n",
       "      <td>7.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984 (Signet Classics (Paperback))</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>7.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>The World's Last Mysteries</td>\n",
       "      <td>Reader's Digest</td>\n",
       "      <td>7.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Word for Every Day</td>\n",
       "      <td>Alvin N. Rogness</td>\n",
       "      <td>7.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Jewels of Elvish</td>\n",
       "      <td>Nancy Varian Berberick</td>\n",
       "      <td>7.275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Book-Title             Book-Author  \\\n",
       "17  Other People's Skeletons (Rebecca Schwartz Mys...             Julie Smith   \n",
       "3                  1984 (Signet Classics (Paperback))           George Orwell   \n",
       "57                         The World's Last Mysteries         Reader's Digest   \n",
       "74                                 Word for Every Day        Alvin N. Rogness   \n",
       "55                                   Jewels of Elvish  Nancy Varian Berberick   \n",
       "\n",
       "    Predicted-Rating  \n",
       "17             7.275  \n",
       "3              7.275  \n",
       "57             7.275  \n",
       "74             7.275  \n",
       "55             7.275  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hybrid Recommendation System\n",
    "\"\"\"\n",
    "Generate hybrid book recommendations for a user.\n",
    "\n",
    "Parameters:\n",
    "- content_row: DataFrame row representing the user and book information.\n",
    "- top_n: Number of top recommendations to return.\n",
    "- collaborative_model: Function for collaborative filtering recommendations.\n",
    "- content_model: Function for content-based recommendations.\n",
    "\n",
    "Returns:\n",
    "- DataFrame containing the top hybrid book recommendations.\n",
    "\"\"\"\n",
    "def hybrid_recommendations(content_row, top_n, collaborative_model=collaborative_recommendations, content_model=content_based_recommendations):\n",
    "    # Extract data from row\n",
    "    book_title = content_row['Book-Title'].values[0]\n",
    "    book_author = content_row['Book-Author'].values[0]\n",
    "    user_id = content_row['User-ID'].values[0]\n",
    "\n",
    "    # Get content-based recommendations for the user\n",
    "    book_recommendations = content_based_recommendations(book_title, book_author, top_n)\n",
    "\n",
    "    # Create an empty DataFrame to store the predicted ratings\n",
    "    predictions_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through content-based recommendations\n",
    "    for index, row in book_recommendations.iterrows():\n",
    "        book_title = row['Book-Title']\n",
    "        book_author = row['Book-Author']\n",
    "        book_isbn = row['ISBN']\n",
    "\n",
    "        # Predict the rating using collaborative filtering\n",
    "        predicted_rating = collaborative_recommendations(user_id, book_isbn)\n",
    "\n",
    "        # Append the results to the DataFrame\n",
    "        predictions_df = pd.concat([predictions_df, pd.DataFrame({'Book-Title': [book_title], 'Book-Author': [book_author], 'Predicted-Rating': [predicted_rating]})], ignore_index=True)\n",
    "\n",
    "    # Sort the DataFrame based on predicted ratings\n",
    "    predictions_df = predictions_df.sort_values(by='Predicted-Rating', ascending=False)\n",
    "    print('------------------------')\n",
    "    print(predictions_df)\n",
    "\n",
    "    # Get the top 5 books\n",
    "    top_hybrid_books = predictions_df.head(5)\n",
    "\n",
    "    return top_hybrid_books\n",
    "\n",
    "# Assuming you have a DataFrame named test_data\n",
    "random_row = merged_df.sample(n=1)  # Use a specific random_state for reproducibility\n",
    "\n",
    "# Display the randomly selected row\n",
    "print(\"Randomly Selected Row:\")\n",
    "print(random_row[['User-ID', 'Book-Title', 'Book-Author']])\n",
    "\n",
    "hybrid_recommendations(random_row, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From random row, gives recommended books using content-based filtering, then uses collab. based filtering to give a predicted rating for the user. Orders from highest to lowest rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLLABRATIVE FILTERING STATS CSV COMPILER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qg1t5VTTUA7Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV String:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "stats_df = pd.DataFrame({\"User-ID\": [],\"ISBN\": [],\"Predicted-Rating\":[],\"Actual-Rating\":[]})\n",
    "\n",
    "for i in range(200):\n",
    "    # Get a random user from the test set\n",
    "    user_id = test_data.sample(n=1)['User-ID'].values[0]\n",
    "    # get a random book from the test set that the user has rated\n",
    "    book_isbn = test_data[test_data['User-ID'] == user_id].sample(n=1)['ISBN'].values[0]\n",
    "\n",
    "    predicted_rating = collaborative_recommendations(user_id, book_isbn)\n",
    "\n",
    "    stats_df.loc[len(stats_df.index)] = [user_id, book_isbn, predicted_rating,test_data[(test_data['User-ID'] == user_id) & (test_data['ISBN'] == book_isbn)]['Book-Rating'].values[0]] \n",
    "\n",
    "stats_csv_data = stats_df.to_csv('stats.csv', index = False) \n",
    "print('\\nCSV String:\\n', stats_csv_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "cN0ElrkA3pZI",
    "z975ITU63ntV"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "054c096e4d4b57417bb781656d4f5218b0e3c2d49c7047d1ff7347fb636be8e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
